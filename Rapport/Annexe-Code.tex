\section{Code informatique}
\begin{verbatim}

library(actuar)
library(ReIns)
library(QRM)

# 1.Norwegian Fire ----------------------------------------------------------
data("norwegianfire")

summary(norwegianfire$size)
#nombre d observation par ann?e
m <- sapply(72:92,function(t){
  sum(norwegianfire$year==t)  
})
#Moyenne des 3 derni?res ann?es
round(mean(m[18:20]),0)

t <- 1:21
#Graphique freq
plot(t,cumsum(m),ylab="Nombre cumulÃ©",main = "Fonction cumulative")
hist(norwegianfire$year,main = "")
title("Histogramme du nombre de sinistre ? chaque ann?e durant la p?riode de 1972 ? 1992")
#Graphique Sev
MeanExcess(norwegianfire$size, k=FALSE,main = "")
title("Fonction d'exc?s moyen")

hist(norwegianfire$size)
title("Histogramme du montant des r?clamations en exc?dent de 500 couronnes")
hist(log(norwegianfire$size/500))
title("Histogramme du log des montant des r?clamations en exc?dent de 500 couronnes")
ExpQQ(norwegianfire$size[norwegianfire$size<10000])
ParetoQQ(norwegianfire$size)
# 1.1.Analyse Frequence -------------------------------------------------------
#Processus de Poisson - Homog?ne
#Le mle d'un PPH est la moyenne empirique
mle_homo <- mean(m)
#On calcule le log de la vraisemblance pour faire un teste de ratio
l_vrais_homo <- sum(log(dpois(m,mle_homo)))

#Processus de Poisson - Nonhomog?ne - Intensit? lin?aire
neg_log_vrais <- function(para){
  -sum(log(dpois(m,para[1] + para[2] * (2*(t-1)+1) / 2)))
}

mle_nonhomo <- constrOptim(c(50, 10), neg_log_vrais, grad = NULL, 
                           ui = c(1,0), ci = 0,outer.eps = .Machine$double.eps)
#Mle du PPNH
mle_nonhomo$par

#test visuel d'ad?quation avec la fr?quence cumul?e
plot(t,cumsum(m))
lines(t,mle_nonhomo$par[1]*(t) + mle_nonhomo$par[2]*(t)^2 / 2,col='red')
lines(t, mean(m)*(t),col='green')
#le PPNH (rouge) semble plus ad?quate que le PPH (vert) 

#V?rification si N(t)/t tends vers la moyenne (Test pour PP)
plot(t,cumsum(m)/(t),type = "l",ylab = "N(t)/t",xlab="t")
lines(t,rep(mean(m),length(t)),col='red')
#On n'a pas assez de donn?es pour tirer une conculsion

#Estimation du nombre de sinistre esp?r?e pour la prochaine ann?e pour un PPNH
est <- mle_nonhomo$par[1]*22 + mle_nonhomo$par[2]*22^2 / 2-mle_nonhomo$par[1]*21 - mle_nonhomo$par[2]*21^2 / 2

#test de ratio de vraisemblance (PPH vs PPNH)
R <- 2*(-mle_nonhomo$value-l_vrais_homo)
qchisq(0.95,1)
1-pchisq(R,1)
#On rejette H0 (poisson homog?ne) --> on choisit le mod?le nonhomog?ne

#Processus de Poisson - Nonhomog?ne - Intensit? exponentielle

intensite <- function(t,para){
  (para[1] * t)^para[2]
}

neg_log_vrais <- function(para){
  -sum(log(dpois(m,intensite(t,para)-intensite(t-1,para))))
}

mle_nonhomo_wei <- constrOptim(c(400, 1), neg_log_vrais, grad = NULL, 
                               ui = c(1,0), ci = 0,outer.eps = .Machine$double.eps)
#Mle PPNH exponentielle
mle_nonhomo_wei$par

#test visuel d'ad?quation avec la fr?quence cumul?e
plot(t,cumsum(m))
lines(t,intensite(t,mle_nonhomo_wei$par),col='blue')
lines(t,mle_nonhomo$par[1]*(t) + mle_nonhomo$par[2]*(t)^2 / 2,col='red')
lines(t, mean(m)*(t),col='green')
#Les deux PPNH sont tr?s proche l'un de l'autre

# 1.2.Analyse severite univariee ------------------------------------------
b <- norwegianfire$size
b_ord <- b[order(b)]
#Distr. empirique
F_B <- function(x){
  sum(b<=x)/length(b)
}

# 1.2.1.Loi Exponentielle
neg_log_vrais <- function(para){
  -sum(log(dexp(b,1/para)/(1-pexp(500,1/para))))
}

mle_exp <- optimize(neg_log_vrais,c(0,3000),tol=.Machine$double.eps)
mle_exp$minimum
#V?rification du mle
mean(b)-500


#Test d'ad?quation graphique
p <- sapply(b_ord[b_ord<10000],function(x){F_B(x)})
plot(b_ord[b_ord<10000],qexp(p, 1/mle_exp$minimum)+500,
	xlab="Quantiles observ?s",ylab="Quantiles th?oriques (expo)")
lines(b_ord[b_ord<10000],b_ord[b_ord<10000],col='red')
#Les donn?es ne suive pas une loi expo

# 1.2.2.Loi Pareto (2 param?tres)
neg_log_vrais <- function(para){
  -sum(log(dpareto(b,para[1],para[2])/(1-ppareto(500,para[1],para[2]))))
}


mle_pareto <- constrOptim(c(1.53, 400), neg_log_vrais, grad = NULL, 
                          ui = diag(2), ci = c(0, 0),outer.eps = .Machine$double.eps)

mle_pareto$par
#On n'a pas des bonnes valeurs de d?part

#test d'ad?quation graphique
n <- length(b_ord)
p <- (1:n)/(1+n)
p <- p+(1-p)* ppareto(500,mle_pareto$par[1],mle_pareto$par[2])
plot(b_ord,qpareto(p,mle_pareto$par[1],mle_pareto$par[2]),xlab="Quantilesobserv?s"
	,ylab="Quantiles th?oriques (log norm)")
lines(b_ord,b_ord,col='red')

# 1.2.3. Loi log normal
neg_log_vrais <- function(para){
  -sum(log(dlnorm(b,para[1],para[2])/(1-plnorm(500,para[1],para[2]))))
}


mle_lnorm <- constrOptim(c(7, 1), neg_log_vrais, grad = NULL, 
                         ui = c(0,1), ci = 0,outer.eps = .Machine$double.eps)
mle_lnorm$par




exp(mle_lnorm$par[1]+mle_lnorm$par[2]^2/2)

#test d'ad?quation graphique
n <- length(b_ord)
p <- (1:n)/(1+n)
p <- p+(1-p)* plnorm(500,mle_lnorm$par[1],mle_lnorm$par[2])
plot(b_ord,qlnorm(p,mle_lnorm$par[1],mle_lnorm$par[2]),xlab="Quantiles observ?s",
	ylab="Quantiles th?oriques (log norm)")
lines(b_ord,b_ord,col='red')

p <- sapply(b_ord[b_ord<10000],function(x){F_B(x)})
p <- p+(1-p)* plnorm(500,mle_lnorm$par[1],mle_lnorm$par[2])
plot(b_ord[b_ord<10000],qlnorm(p,mle_lnorm$par[1],mle_lnorm$par[2]),
	xlab="Quantiles observ?s",ylab="Quantiles th?oriques (log norm)")
lines(b_ord[b_ord<10000],b_ord[b_ord<10000],col='red')
#Mod?le ad?quate pour des valeurs inf?rieurs ? 10000

p_obs <- sapply(b_ord,function(x){F_B(x)})
p_theo <- (plnorm(b_ord,mle_lnorm$par[1],mle_lnorm$par[2])-plnorm(500,
	mle_lnorm$par[1],mle_lnorm$par[2]))/(1-plnorm(500,mle_lnorm$par[1],mle_lnorm$par[2]))
ks.test(p_obs,p_theo)
#Mod?le ad?quate


# 1.3.Analyse severite splicing -------------------------------------------

# 1.3.1.LN-Pareto (continue & d?rivable) ------------------------------------------------------------------
LOSS <- sort(norwegianfire$size)
b_ord <- LOSS
#On fixe mu (continue & d?rivable)
mu <- function(para){
  log(para[1]) - para[2] * para[3]^2
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}
#On fixe w (continue & d?rivable)
w <- function(para){
  FF(para) * para[2] * para[3] * sqrt(2*pi) * 
  exp(para[2]^2*para[3]^2/2) / (1+FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]^2*para[3]^2/2))
}

#Partie log normal
f_1 <- function(x,para){
  dlnorm(x,mu(para),para[3])
}
#Partie Pareto
f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}
#Densit? de la loi compos?e
f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* plnorm(500,mu(para),para[3])/FF(para))
}




mle_LN_pa <- constrOptim(c(1287,1.29,0.82),neg_log_vrais,
	grad =NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)

#Mle de la loi compos?e
mle_LN_pa

mu(mle_LN_pa$par)

w(mle_LN_pa$par)

#Fonction Quantile
F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv <- function(u){
  if(u <= w(mle_LN_pa$par)){
    qlnorm(u * FF(mle_LN_pa$par) / w(mle_LN_pa$par) , 
    	mu(mle_LN_pa$par), mle_LN_pa$par[3])
  }else{
    F_x_2_inv((u-w(mle_LN_pa$par)) / (1-w(mle_LN_pa$par)),mle_LN_pa$par[2],mle_LN_pa$par[1])
  }
}

#Ad?quation graphique support complet
F_d <- w(mle_LN_pa$par)*plnorm(500,mu(mle_LN_pa$par),
	mle_LN_pa$par[3])/FF(mle_LN_pa$par)
t1 <- mle_LN_pa$par[1]
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (log norm - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_LN_pa$par[1],col=3)
title("QQPlot LN-Pa cont. et d?riv.")

#Ad?quation graphique support premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
p <- p+F_d * (1-p)
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (Weibull - pareto -pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa cont. et d?riv.")
F_B(t1)

F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * plnorm(x,mu(para),para[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}


FFF <- function(x){
  (sapply(x,F_X,para=mle_LN_pa$par)-F_d)/(1-F_d)
}

#Test d'Anderson-Darling
(AD_LN_Pa <- goftest::ad.test(LOSS,FFF))
#Pas ad?quate

#Calcule du AIC et BSC
AIC_LN_pa <- 2 * length(mle_LN_pa$par) + 2* mle_LN_pa$value 
BSC_LN_pa <- length(mle_LN_pa$par) * log(length(LOSS)) + 2 * mle_LN_pa$value
# 1.3.2.LN-Pareto choix du t1 ------------------------------------------------------

#On choisit le points de la coupure
t1 <- b_ord[9100]
w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
MeanExcess(norwegianfire$size, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)





LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA1 <- sort(LOSS[LOSS>t1])


F_1 <- function(x,para){
  plnorm(x,para[1],para[2])
}

f_2 <- function(x,para){
  t1^para * para / x^(para+1)
}


f_1 <- function(x,para){
  dlnorm(x,para[1],para[2])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(500,para))
}
neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA1,function(l) log(f_2(l,para))))
}


mle_MD_LN <-  constrOptim(c(6,1),neg_log_vrais_MD,grad = NULL,
	ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)
mle_pa1_LN <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum

#mle de la partie log normal
mle_MD_LN
#mle des valeurs extr?mes (pareto)
mle_pa1_LN

#Fonctions quantiles
F_x_2_inv <- function(u,theta,alpha){
  (1-u)^(-1/alpha) * theta
}

F_X_inv <- function(u){
  if(u <= w1){
    qlnorm(u * (F_1(t1,mle_MD_LN$par)-F_1(500,mle_MD_LN$par))/ w1 +
    	F_1(500,mle_MD_LN$par) ,mle_MD_LN$par[1],mle_MD_LN$par[2])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,t1,mle_pa1_LN)
  }  
}
F_d <- w1* F_1(500,mle_MD_LN$par)/ F_1(t1,mle_MD_LN$par)

#Test Ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (LN - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa")

#Test Ad?quation graphique premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_LN$par)-F_1(500,mle_MD_LN$par)) * f_1(x,mle_MD_LN$par)
  }else{
    (1-w1) * f_2(x,mle_pa1_LN)
  }
}

#V?rification graphique du la continuit?
x <- seq(1,20000,by=1)
plot(x,sapply(x,f_X),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-20,t1+20,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

#V?rification graphique du la continuit?
F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    (F_1(x,mle_MD_LN$par)-F_1(500,mle_MD_LN$par)) * w1 / (F_1(t1,mle_MD_LN$par)-F_1(500,mle_MD_LN$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_LN))
  }
}
F_X(501)

#Test d'Anderson-Darling
F_d <- F_X(500)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
(AD_LN_Pa_2 <- goftest::ad.test(LOSS,FFF))

#Calcule du AIC et BSC
AIC_LN_pa_2 <- 2 * 3 - 2* sum(log(sapply(LOSS,f_X)))
BSC_LN_pa_2 <- 3 * log(length(LOSS)) - 2 *  sum(log(sapply(LOSS,f_X)))

# 1.3.3.LN-Pareto G?n?ralis?e (continue & d?rivable)  -------------------------------------------------------------

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]

#On fixe mu (continue & d?rivable)
mu <- function(para){
  (log(para[1]) - para[2]*para[1] * para[3]^2 / (para[4]+para[1])) / (1 - para[3]^2 / (para[4]+para[1]))
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}
#On fixe w (continue & d?rivable)
w <- function(para){
  FF(para) * para[1] * para[2] * para[3] * sqrt(2*pi) * exp( (log(para[1])-mu(para))^2 / (2*para[3]^2 )) / (para[1]+para[4]+FF(para) * para[1] * para[2] * para[3] * sqrt(2*pi) * exp( (log(para[1])-mu(para))^2 / (2*para[3]^2 )))
}


f_1 <- function(x,para){
  dlnorm(x,mu(para),para[3])
}
f_2 <- function(x,para){
  para[2] * (para[1]+para[4])^para[2] / (para[4]+x)^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* plnorm(500,mu(para),para[3])/FF(para))
}




mle_LN_PG <- constrOptim(c(2202,1.32,1.14,-17),neg_log_vrais,grad = NULL,
	ui=matrix(c(1,0,0,0,1,0,0,0,1,0,0,0),3,4),ci=c(0,0,0),
		outer.eps = .Machine$double.eps)

#Mle de la loi compos?
mle_LN_PG

FF(mle_LN_PG$par)

w(mle_LN_PG$par)

F_x_2_inv <- function(u,alpha,theta,lambda){
  (1-u)^(-1/alpha) * (theta+lambda) - lambda
}
F_X_inv <- function(u){
  if(u <= w(mle_LN_PG$par)){
    qlnorm(u * FF(mle_LN_PG$par) / w(mle_LN_PG$par) ,
    	 mu(mle_LN_PG$par), mle_LN_PG$par[3])
  }else{
    F_x_2_inv((u-w(mle_LN_PG$par)) / (1-w(mle_LN_PG$par)),mle_LN_PG$par[2],
    	mle_LN_PG$par[1],mle_LN_PG$par[4])
  }
}
F_d <- w(mle_LN_PG$par)*plnorm(500,mu(mle_LN_PG$par),
	mle_LN_PG$par[3])/FF(mle_LN_PG$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (LN - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_LN_PG$par[1],col=3)
title("QQPlot LN-PG cont. et d?riv.")
t1 <- mle_LN_PG$par[1]
#Test d'ad?quation graphique premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
p <- p+F_d * (1-p)
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],
	ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-PG cont. et d?riv.")
F_B(t1)


F_2 <- function(x,para){
  1- ((para[1]+para[4])/(x+para[4]))^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * plnorm(x,mu(para),para[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

FFF <- function(x){
  (sapply(x,F_X,para=mle_LN_PG$par)-F_d)/(1-F_d)
}
#Test d'Anderon-Darling
AD_LN_PG <- goftest::ad.test(LOSS,FFF)
#Calcule du AIC et BSC
AIC_LN_PG <- 2 * length(mle_LN_PG$par) + 2* mle_LN_PG$value 
BSC_LN_PG <- length(mle_LN_PG$par) * log(length(LOSS)) + 2 * mle_LN_PG$value

# 1.3.4.LN-Pareto G?n?ralis?e choix du t1 -----------------------------------------------

#On choisit le point de coupure t1
t1 <- b_ord[9100]
w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
MeanExcess(norwegianfire$size, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)




#On coupe les donn?es en deux parties
LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_GP <- sort(LOSS[LOSS>t1])


F_1 <- function(x,para){
  plnorm(x,para[1],para[2])
}

f_2 <- function(x,para){
  (para[1]+t1)^(para[2]) * para[2] / (para[1]+x)^(para[2]+1)
}


f_1 <- function(x,para){
  dlnorm(x,para[1],para[2])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+
  		length(LOSS_MD) * log(F_1(t1,para)-F_1(500,para))
}
neg_log_vrais_PG <- function(para){
  -sum(sapply(LOSS_GP,function(l) log(f_2(l,para))))
}


mle_MD_LN <-  constrOptim(c(6,1),neg_log_vrais_MD,
	grad = NULL,ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)
mle_GP <- constrOptim(c(1,1),neg_log_vrais_PG,
	grad = NULL,ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)

#Mle de la partie LN
mle_MD_LN
#Mle de la pareto gen. (valeurs extr?mes)
mle_GP

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-((para[3]+t1)/(para[3]+x))^(para[4]))
  }  
}


F_x_2_inv <- function(u,lambda,theta,alpha){
  (1-u)^(-1/alpha) * (theta+lambda) -lambda
}

F_X_inv <- function(u){
  if(u <= w1){
    qlnorm(u * (F_1(t1,mle_MD_LN$par)-F_1(500,mle_MD_LN$par))/ w1 +
    	 F_1(500,mle_MD_LN$par) ,mle_MD_LN$par[1],mle_MD_LN$par[2])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_GP$par[1],t1,mle_GP$par[2])
  }  
}
F_d <- w1* F_1(500,mle_MD_LN$par)/ F_1(t1,mle_MD_LN$par)

#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (LN - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-PG")
#Test d'ad?quation graphique de la partie Log normale
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-PG")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_LN$par)-F_1(500,mle_MD_LN$par)) * f_1(x,mle_MD_LN$par)
  }else{
    (1-w1) * f_2(x,mle_GP$par)
  }
}

#V?rification graphique de la discontinuit?
x <- seq(1,20000,by=1)
plot(x,sapply(x,f_X),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-20,t1+20,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)


F_2 <- function(x,para){
  1- ((para[1]+t1)/(x+t1))^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    w1 / (F_1(t1,mle_MD_LN$par)-F_1(500,mle_MD_LN$par)) *	
    	(F_1(x,mle_MD_LN$par)-F_1(500,mle_MD_LN$par))
  }else{
    w1 + (1-w1) * F_2(x,mle_GP$par)
  }
}


F_d <- F_X(500)

FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
#Test d'Anderson-Darling
(AD_LN_PG_2 <- goftest::ad.test(LOSS,FFF))
#Calcule du AIC et BSC
AIC_LN_PG_2 <- 2 * 3 - 2* sum(log(sapply(LOSS,f_X)))
BSC_LN_PG_2 <- 3 * log(length(LOSS)) - 2 *  sum(log(sapply(LOSS,f_X)))

# 1.3.5.LN-Pareto-Pareto ----------------------------------------------------------

#On choisit le deuxi?me point de compure.
#La premi?re partie est une LN-Pareto et le deuxi?me 
	une Pareto (on ignore la continuit?
# la d?rivabilit? au point t1)
w1 <- 0.995
t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
MeanExcess(norwegianfire$size, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)





LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA <- sort(LOSS[LOSS>t1])
mu <- function(para){
  log(para[1]) - para[2] * para[3]^2
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}

w <- function(para){
  FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]*para[3]^2/2) / (1+FF(para) *
  	 para[2] * para[3] * sqrt(2*pi) * exp(para[2]*para[3]^2/2))
}


f_1 <- function(x,para){
  dlnorm(x,mu(para),para[3])
}
f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) * plnorm(x,mu(para),para[3])/FF(para)
  }
  else{
    w(para) + (1-w(para) ) * (1-(para[1]/x)^(para[2]))
  }  
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_X(l,para))))+length(LOSS_MD) * log(F_X(t1,para)-F_X(500,para))
}


mle_MD_LN_pa <- constrOptim(c(1287,1.29,0.82),neg_log_vrais,
		grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)


f_3 <- function(x,para){
  t1^para * para / x^(para+1)
}


neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA,function(l) log(f_3(l,para))))
}
#Mle de la premi?re partie
mle_MD_LN_pa

mle_pa1_LN <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum
#Mle de la deuxi?me partie
mle_pa1_LN

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv_1 <- function(u){
  if(u <= w(mle_MD_LN_pa$par)){
    qlnorm(u * FF(mle_MD_LN_pa$par)/ w(mle_MD_LN_pa$par),
    	 mu(mle_MD_LN_pa$par), mle_MD_LN_pa$par[3])
  }else{
    F_x_2_inv((u-w(mle_MD_LN_pa$par)) / (1-w(mle_MD_LN_pa$par)),mle_MD_LN_pa$par[2],mle_MD_LN_pa$par[1])
  }
}

F_X_inv <- function(u){
  if(u <= w1){
    F_X_inv_1(u/w1 * (F_X(t1,mle_MD_LN_pa$par)-
    	F_X(500,mle_MD_LN_pa$par))+ F_X(500,mle_MD_LN_pa$par))
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_pa1_LN,t1)
  }  
}
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (LN - pareto - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_MD_LN_pa$par[1],col=3)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa-Pa")

#Test d'ad?quation graphique de la premi?re partie (LN-Pareto)
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (LN - pareto - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa-Pa")



F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
FF_X <- function(x){
  if(x <= t1){
    (F_X(x,mle_MD_LN_pa$par)-F_X(500,mle_MD_LN_pa$par)) * 
    	w1 / (F_X(t1,mle_MD_LN_pa$par)-F_X(500,mle_MD_LN_pa$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_LN))
  }
}

F_d <- FF_X(500)
FFF <- function(x){
  (sapply(x,FF_X)-F_d)/(1-F_d)
}
#Test d'Anderson-Darling
(AD_LN_Pa_Pa<- goftest::ad.test(LOSS,FFF))
#Calcule du AIC et BSC
ff_X <- function(x){
  if(x<=t1){
    w1/(F_X(t1,mle_MD_LN_pa$par)-F_X(500,mle_MD_LN_pa$par)) * f_X(x,mle_MD_LN_pa$par)
  }else{
    (1-w1) * f_3(x,mle_pa1_LN)
  } 
}
AIC_LN_pa_pa <- 2 * 4- 2* sum(log(sapply(LOSS,ff_X)))
BSC_LN_pa_pa <- 4 * log(length(LOSS)) - 2* sum(log(sapply(LOSS,ff_X)))

# 1.3.6.Weibull-Pareto (continue & d?rivable) -----------------------------------------------------------


LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]

#On fixe le beta (continuit? & d?rivabilit?) de la Weibull
beta <- function(para){
  para[1] / (para[2]/para[3]+1)^(1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}
#On fixe w (continuit? & d?rivabilit?)
w <- function(para){
  (exp(para[2]/para[3]+1)-1) / (exp(para[2]/para[3]+1)+para[3]/para[2])
}


f_1 <- function(x,para){
  dweibull(x,para[3],beta(para))
}
f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * 
  	log(1-w(para)* pweibull(500,para[3],beta(para))/FF(para))
}




mle_Wei_pa <- constrOptim(c(1945,1.3242,0.59),neg_log_vrais,grad = NULL,
	ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)
#Mle de la partie Weibull
mle_Wei_pa

beta(mle_Wei_pa$par)

w(mle_Wei_pa$par)

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv <- function(u){
  if(u <= w(mle_Wei_pa$par)){
    qweibull(u * FF(mle_Wei_pa$par) / w(mle_Wei_pa$par) ,
    	 mle_Wei_pa$par[3],beta(mle_Wei_pa$par))
  }else{
    F_x_2_inv((u-w(mle_Wei_pa$par)) /
    	 (1-w(mle_Wei_pa$par)),mle_Wei_pa$par[2],mle_Wei_pa$par[1])
  }
}
F_d <- w(mle_Wei_pa$par)*pweibull(500,mle_Wei_pa$par[3],
	beta(mle_Wei_pa$par))/FF(mle_Wei_pa$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (Weibull - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_Wei_pa$par[1],col=3)
title("QQPlot Weibull - Pareto cont. et d?riv.")
t1 <- mle_Wei_pa$par[1]
x <- t1+100
#Test d'ad?quation premi?re partie
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],
	ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto cont. et d?riv.")
F_B(t1)


F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * pweibull(x,para[3],beta(para))}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

FFF <- function(x){
  (sapply(x,F_X,para=mle_Wei_pa$par)-F_d)/(1-F_d)
}
#Test d'Anderon-Darling
(AD_Wei_Pa<- goftest::ad.test(LOSS,FFF))


#Calcule du AIC et BSC
AIC_Wei_pa <- 2 * 3 + 2* mle_Wei_pa$value
BSC_Wei_pa <- 3 * log(length(LOSS)) + 2*mle_Wei_pa$value
LOG_VRAIS_Wei_pa <- -mle_Wei_pa$value

# 1.3.7.Weibull-Pareto choix du t1  --------------------------------------------------------

#On choisit t1
t1 <- b_ord[9100]
w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
MeanExcess(norwegianfire$size, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)

LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA1 <- sort(LOSS[LOSS>t1])

F_1 <- function(x,para){
  pweibull(x,para[1],para[2])
}

f_2 <- function(x,para){
  t1^para * para / x^(para+1)
}


f_1 <- function(x,para){
  dweibull(x,para[1],para[2])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) *
  	 log(F_1(t1,para)-F_1(500,para))
}
neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA1,function(l) log(f_2(l,para))))
}


mle_MD_Wei <-  constrOptim(c(1/2,1),neg_log_vrais_MD,grad =
	 NULL,ui=diag(2),ci=c(0,0),outer.eps = .Machine$double.eps)
mle_pa1_Wei <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum
#Mle de la Weibull
mle_MD_Wei
#Mle de la Pareto
mle_pa1_Wei

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-(t1/x)^(para[3]))
  }  
}


F_x_2_inv <- function(u,theta,alpha){
  (1-u)^(-1/alpha) * theta
}

F_X_inv <- function(u){
  if(u <= w1){
    qweibull(u * (F_1(t1,mle_MD_Wei$par)-F_1(500,mle_MD_Wei$par))/
    	 w1 + F_1(500,mle_MD_Wei$par) ,mle_MD_Wei$par[1],mle_MD_Wei$par[2])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,t1,mle_pa1_Wei)
  }  
}
F_d <- w1* F_1(500,mle_MD_Wei$par)/ F_1(t1,mle_MD_Wei$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (Weibull - Pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto")
#Test d'ad?quation graphique premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],
	ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_Wei$par)-F_1(500,mle_MD_Wei$par))
    	 * f_1(x,mle_MD_Wei$par)
  }else{
    (1-w1) * f_2(x,mle_pa1_Wei)
  }
}

#V?rification de la discontinuit? au point t1
x <- seq(t1-20,t1+20,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    (F_1(x,mle_MD_Wei$par)-F_1(500,mle_MD_Wei$par)) * 
    	w1 / (F_1(t1,mle_MD_Wei$par)-F_1(500,mle_MD_Wei$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_Wei))
  }
}
F_X(501)

F_d <- F_X(500)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
#Test d'Anderson Darling
(AD_Wei_Pa_2<- goftest::ad.test(LOSS,FFF))
#Calcul du AIC et BSC
AIC_Wei_pa_2 <- 2 * 3 - 2* sum(log(sapply(LOSS,f_X)))
BSC_Wei_pa_2 <- 3 * log(length(LOSS)) - 2*sum(log(sapply(LOSS,f_X)))

# 1.3.8.Weibull-Pareto G?n?ralis?e (continue & d?rivable) --------------------------------------------------------

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
#On fixe beta (continue & d?rivable) de la Weibull
beta <- function(para){
  para[1] * ( (para[2] * para[1] -para[4])/ 
  	((para[4]+para[1])*para[3]) + 1)^(-1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}
#On fixe le w
w <- function(para){
  (exp((para[1]/beta(para))^para[3])-1) / ( (para[3]/para[2]) * 
  	(para[4]/para[1]+1) * (para[1]/beta(para))^para[3] +  exp((para[1]/beta(para))^para[3])-1) 
}

f_1 <- function(x,para){
  dweibull(x,para[3],beta(para))
}
f_2 <- function(x,para){
  para[2] * (para[1]+para[4])^para[2] / (para[4]+x)^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS)
  		 * log(1-w(para)* pweibull(500,para[3],beta(para))/FF(para))
}




mle_Wei_PG <- constrOptim(c(1081,1.38,0.9,153),neg_log_vrais,
	grad = NULL,ui=matrix(c(1,0,0,0,1,0,0,0,1,0,0,0),3,4),
		ci=c(0,0,0),outer.eps = .Machine$double.eps)

#Mle de la loi compos?e
mle_Wei_PG

beta(mle_Wei_PG$par)

w(mle_Wei_PG$par)

F_x_2_inv <- function(u,alpha,theta,lambda){
  (1-u)^(-1/alpha) * (theta+lambda) - lambda
}
F_X_inv <- function(u){
  if(u <= w(mle_Wei_PG$par)){
    qweibull(u * FF(mle_Wei_PG$par) / w(mle_Wei_PG$par) , mle_Wei_PG$par[3],beta(mle_Wei_PG$par))
  }else{
    F_x_2_inv((u-w(mle_Wei_PG$par)) / (1-w(mle_Wei_PG$par)),mle_Wei_PG$par[2],
    	mle_Wei_PG$par[1],mle_Wei_PG$par[4])
  }
}
F_d <- w(mle_Wei_PG$par)*pweibull(500,mle_Wei_PG$par[3],
	beta(mle_Wei_PG$par))/FF(mle_Wei_PG$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (Weibull - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_Wei_PG$par[1],col=3)
title("QQPlot Weibull - PG cont. et d?riv.")
#Test d'ad?quation graphique premi?re partie
t1 <- mle_Wei_PG$par[1]
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],
	ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - PG cont. et d?riv.")
F_B(t1)

F_2 <- function(x,para){
  1- ((para[1]+para[4])/(x+para[4]))^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * pweibull(x,para[3],beta(para))}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

FFF <- function(x){
  (sapply(x,F_X,para=mle_Wei_PG$par)-F_d)/(1-F_d)
}
#Test d'Anderson-Darling
(AD_Wei_PG<- goftest::ad.test(LOSS,FFF))
#Calcule du AIC et BSC
AIC_Wei_PG <- 2 * 4 + 2* mle_Wei_PG$value
BSC_Wei_PG <- 4 * log(length(LOSS)) + 2*mle_Wei_PG$value

# 1.3.9.Weibull-Pareto G?n?ralis?e choix du t1 -----------------------------------------------

#On choisit le point de coupure t1
t1 <- b_ord[9100]
w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
MeanExcess(norwegianfire$size, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)

LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_GP <- sort(LOSS[LOSS>t1])

F_1 <- function(x,para){
  pweibull(x,para[1],para[2])
}

f_2 <- function(x,para){
  (para[1]+t1)^(para[2]) * para[2] / (para[1]+x)^(para[2]+1)
}


f_1 <- function(x,para){
  dweibull(x,para[1],para[2])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(500,para))
}
neg_log_vrais_PG <- function(para){
  -sum(sapply(LOSS_GP,function(l) log(f_2(l,para))))
}


mle_MD_Wei <-  constrOptim(c(1/2,1),neg_log_vrais_MD,grad = NULL,ui=diag(2),ci=c(0,0),outer.eps = .Machine$double.eps)
mle_GP <- constrOptim(c(1,1),neg_log_vrais_PG,grad = NULL,
	ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)
#Mle de la Weibull
mle_MD_Wei
#Mle de la PG
mle_GP

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-((para[3]+t1)/(para[3]+x))^(para[4]))
  }  
}


F_x_2_inv <- function(u,lambda,theta,alpha){
  (1-u)^(-1/alpha) * (theta+lambda) -lambda
}

F_X_inv <- function(u){
  if(u <= w1){
    qweibull(u * (F_1(t1,mle_MD_Wei$par)-F_1(500,mle_MD_Wei$par))/ 
    	w1 + F_1(500,mle_MD_Wei$par) ,mle_MD_Wei$par[1],mle_MD_Wei$par[2])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_GP$par[1],t1,mle_GP$par[2])
  }  
}
F_d <- w1* F_1(500,mle_MD_Wei$par)/ F_1(t1,mle_MD_Wei$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (Weibull - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto g?n?ralsi?e")
#Test d'ad?quation graphique de la premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],
	ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto g?n?ralsi?e")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_Wei$par)-F_1(500,mle_MD_Wei$par)) *
    	 f_1(x,mle_MD_Wei$par)
  }else{
    (1-w1) * f_2(x,mle_GP$par)
  }
}

F_2 <- function(x,para){
  1- ((para[1]+t1)/(x+t1))^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    w1 / (F_1(t1,mle_MD_Wei$par)-F_1(500,mle_MD_Wei$par)) *
    	 (F_1(x,mle_MD_Wei$par)-F_1(500,mle_MD_Wei$par))
  }else{
    w1 + (1-w1) * F_2(x,mle_GP$par)
  }
}

F_d <- F_X(500)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
#Test d'Anderson-Darling
(AD_Wei_PG_2<- goftest::ad.test(LOSS,FFF))
#Calcule du AIC et BSC
AIC_Wei_PG_2 <- 2 * 4 - 2* sum(log(sapply(LOSS,f_X)))
BSC_Wei_PG_2 <- 4 * log(length(LOSS)) - 2*sum(log(sapply(LOSS,f_X)))

# 1.3.10.Weibull-Pareto-Pareto -----------------------------------------------------

w1 <- 0.995
#On choisit le point de coupure pour la deuxi?me partie
t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
MeanExcess(norwegianfire$size, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)


LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA <- sort(LOSS[LOSS>t1])
beta <- function(para){
  para[1] / (para[2]/para[3]+1)^(1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}

pexp(1,2)
pweibull(1,1,0.5)

w <- function(para){
  (exp(para[2]/para[3]+1)-1) / (exp(para[2]/para[3]+1)+para[3]/para[2])
}


f_1 <- function(x,para){
  dweibull(x,para[3],beta(para))
}


f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) * pweibull(x,para[3],beta(para))/FF(para)
  }
  else{
    w(para) + (1-w(para) ) * (1-(para[1]/x)^(para[2]))
  }  
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_X(l,para))))+length(LOSS_MD) *
  	 log(F_X(t1,para)-F_X(500,para))
}


mle_MD_Wei_pa <- constrOptim(c(1287,1.29,0.82),neg_log_vrais,
	grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)


f_3 <- function(x,para){
  t1^para * para / x^(para+1)
}


neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA,function(l) log(f_3(l,para))))
}

mle_MD_Wei_pa
mle_pa1_Wei <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum
mle_pa1_Wei

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv_1 <- function(u){
  if(u <= w(mle_MD_Wei_pa$par)){
    qweibull(u * FF(mle_MD_Wei_pa$par)/
    	 w(mle_MD_Wei_pa$par),mle_MD_Wei_pa$par[3],beta(mle_MD_Wei_pa$par))
  }else{
    F_x_2_inv((u-w(mle_MD_Wei_pa$par)) /
    	 (1-w(mle_MD_Wei_pa$par)),mle_MD_Wei_pa$par[2],mle_MD_Wei_pa$par[1])
  }
}

F_X_inv <- function(u){
  if(u <= w1){
    F_X_inv_1(u/w1 * (F_X(t1,mle_MD_Wei_pa$par)-
    	F_X(500,mle_MD_Wei_pa$par))+ F_X(500,mle_MD_Wei_pa$par))
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_pa1_Wei,t1)
  }  
}
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (Weibull - pareto - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_MD_Wei_pa$par[1],col=3)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot WeibullPa-Pa")
#Test d'ad?quation graphique premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",
	xlab="Quantiles th?oriques (Weibull - pareto - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot WeibullPa-Pa")

F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
FF_X <- function(x){
  if(x <= t1){
    (F_X(x,mle_MD_Wei_pa$par)-F_X(500,mle_MD_Wei_pa$par)) *
    	 w1 / (F_X(t1,mle_MD_Wei_pa$par)-F_X(500,mle_MD_Wei_pa$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_Wei))
  }
}

F_d <- FF_X(500)
FFF <- function(x){
  (sapply(x,FF_X)-F_d)/(1-F_d)
}
#Test d'Anderson-Darling
(AD_Wei_Pa_Pa<- goftest::ad.test(LOSS,FFF))

ff_X <- function(x){
  if(x<=t1){
    w1/(F_X(t1,mle_MD_Wei_pa$par)-F_X(500,mle_MD_Wei_pa$par)) 
    	* f_X(x,mle_MD_Wei_pa$par)
  }else{
    (1-w1) * f_3(x,mle_pa1_Wei)
  } 
}
#Calcule du AIC et BSC
AIC_Wei_pa_pa <- 2 * 4- 2* sum(log(sapply(LOSS,ff_X)))
BSC_Wei_pa_pa <- 4 * log(length(LOSS)) - 2* sum(log(sapply(LOSS,ff_X)))

LOG_VRAIS_Wei_pa_pa <- sum(log(sapply(LOSS,ff_X)))

# COXIENNE2---------------------------------------------------------


# fonctions de la loi cox2
fx1 <- function(x,beta1,beta2,p){
  p * beta1*exp(-beta1*x) + (1-p)*(beta1*beta2)*
  	 ( exp(-beta1*x)/(beta2-beta1) + exp(-beta2*x)/(beta1-beta2) )
}

fx1_d <- function(x,beta1,beta2,p){
  -p * beta1^2*exp(-beta1*x) + (1-p)*beta1*beta2* 
  	( - beta1 * exp(-beta1*x)/(beta2-beta1) - beta2 *exp(-beta2*x)/(beta1-beta2) )
}


Fx1 <- function(x,beta1,beta2,p){
  p * (1-exp(-beta1*x)) + (1-p) * ( beta2 * (1-exp(-beta1*x))/(beta2-beta1) +
  	 beta1 *(1-exp(-beta2*x))/(beta1-beta2)
  )}

Fx1_inv <- function(k,beta1,beta2,p){ 
  uniroot(function(x) Fx1(x,beta1,beta2,p) - k, c(0,10^9))$root
}


# 1.3.11.COXIENNE 2-Pareto (continue) ----------------------------------------------------
LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]

FF <- function(para){
  Fx1(para[4],para[1],para[2],para[3])
}

#On fixe w (continuit?)
w <- function(para){
  FF(para) / ( FF(para) + para[4]/para[5] * 
  	fx1(para[4],para[1],para[2],para[3]))
}


f_2 <- function(x,para){
  para[5] * para[4]^para[5] * x^(-para[5]-1)
}

f_X <- function(x,para){
  if(x<=para[4]){
    w(para)/FF(para) * fx1(x,para[1],para[2],para[3])
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+	
  length(LOSS) * log(1-w(para)* Fx1(500,para[1],para[2],para[3])/FF(para))
}

const <- matrix(c(1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,1,0,0,0,0,0,0,1),6,5)
test <- c(0.001,0.0002,0.90,6600,1.28)

mle_cox_pa <- constrOptim(test,neg_log_vrais,grad = NULL,ui=const,ci=c(0,0,0,-1,0,0),outer.eps = .Machine$double.eps)
#Mle de la loi compos?e
mle_cox_pa

w(mle_cox_pa$par)

F_x_2_inv <- function(u,theta,alpha){
  theta * (1-u)^(-1/alpha)
}


F_X_inv <- function(u){
  if(u <= w(mle_cox_pa$par)){
    Fx1_inv (u * FF(mle_cox_pa$par) / w(mle_cox_pa$par) , mle_cox_pa$par[1],mle_cox_pa$par[2],mle_cox_pa$par[3])
  }else{
    F_x_2_inv((u-w(mle_cox_pa$par)) / (1-w(mle_cox_pa$par)),mle_cox_pa$par[4],mle_cox_pa$par[5])
  }
}
F_d <- w(mle_cox_pa$par)* Fx1(500,mle_cox_pa$par[1],mle_cox_pa$par[2],mle_cox_pa$par[3])/FF(mle_cox_pa$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - Pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_cox_pa$par[4],col=3)
title("QQPlot Coxienne2 - Pareto cont.")
t1 <- mle_cox_pa$par[4]
#Test d'ad?quation graphique partie Coxienne-2
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
x <- t1+200
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - Pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto cont.")


f_X <- function(x){
  if(x<=t1){
    w(mle_cox_pa$par)/FF(mle_cox_pa$par) * fx1(x,mle_cox_pa$par[1],mle_cox_pa$par[2],mle_cox_pa$par[3])
  }else{
    (1-w(mle_cox_pa$par))  * f_2(x,mle_cox_pa$par)
  }
}
#V?rification de la continuit? au point t1
x <- seq(t1-20,t1+20,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)


F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * Fx1(x,para[1],para[2],para[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

FFF <- function(x){
  (sapply(x,F_X,para=mle_cox_pa$par)-F_d)/(1-F_d)
}
#Test d'Anderson-Darling
(AD_cox_pa<- goftest::ad.test(LOSS,FFF))

AIC_cox_pa<- 2 * 5 + 2* mle_cox_pa$value
BSC_cox_pa <- 5 * log(length(LOSS)) + 2*mle_cox_pa$value

# 1.3.12.COXIENNE 2-Pareto choix du t1 -----------------------------------------------
#On choisit t1
t1 <- b_ord[9100]
w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
MeanExcess(norwegianfire$size, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)

LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA1 <- sort(LOSS[LOSS>t1])

F_1 <- function(x,para){
  Fx1(x,para[1],para[2],para[3])
}

f_2 <- function(x,para){
  t1^para * para / x^(para+1)
}


f_1 <- function(x,para){
  fx1(x,para[1],para[2],para[3])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(500,para))
}
neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA1,function(l) log(f_2(l,para))))
}


mle_MD_cox <-  constrOptim(c(1/500,1/1000,0.5),neg_log_vrais_MD,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)
mle_pa1_cox <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum
#Mle de la partie coxienne2
mle_MD_cox
mle_pa1_cox

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-(t1/x)^(para[3]))
  }  
}


F_x_2_inv <- function(u,theta,alpha){
  (1-u)^(-1/alpha) * theta
}

F_X_inv <- function(u){
  if(u <= w1){
    Fx1_inv(u * (F_1(t1,mle_MD_cox$par)-F_1(500,mle_MD_cox$par))/ w1 + F_1(500,mle_MD_cox$par) ,mle_MD_cox$par[1],mle_MD_cox$par[2],mle_MD_cox$par[3])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,t1,mle_pa1_cox)
  }  
}
F_d <- w1* F_1(500,mle_MD_cox$par)/ F_1(t1,mle_MD_cox$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - Pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto")
#Test d'ad?quation graphique premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - Pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_cox$par)-F_1(500,mle_MD_cox$par)) * f_1(x,mle_MD_cox$par)
  }else{
    (1-w1) * f_2(x,mle_pa1_cox)
  }
}

#V?rification de la Discontinuit?
x <- seq(t1-20,t1+20,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    (F_1(x,mle_MD_cox$par)-F_1(500,mle_MD_cox$par)) * w1 / (F_1(t1,mle_MD_cox$par)-F_1(500,mle_MD_cox$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_cox))
  }
}
F_X(501)

F_d <- F_X(500)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
#Test d'Anderson-Darling
(AD_cox_pa_2<- goftest::ad.test(LOSS,FFF))
#Calcule du AIC et BSC
AIC_cox_pa_2<- 2 * 4 - 2* sum(log(sapply(LOSS,f_X)))
BSC_cox_pa_2 <- 4 * log(length(LOSS)) - 2*sum(log(sapply(LOSS,f_X)))

# 1.3.13.COXIENNE 2-Pareto G?n?ralis?e (continue) ------------------------------------------------------
LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]

FF <- function(para){
  Fx1(para[4],para[1],para[2],para[3])
}

#On fixe w
w <- function(para){
  FF(para) / ( FF(para) + (para[4]+para[5])/para[6] * fx1(para[4],para[1],para[2],para[3]))
}


f_2 <- function(x,para){
  para[6] * (para[4]+para[5])^para[6] / (x+para[5])^(para[6]+1)
}

f_X <- function(x,para){
  if(x<=para[4]){
    w(para)/FF(para) * fx1(x,para[1],para[2],para[3])
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* Fx1(500,para[1],para[2],para[3])/FF(para))
}


const <- matrix(c(1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1),7,6)
test <- c(0.001,0.0002,0.90,6600,1,1)

#1/500, 1/60,0.5,4000
w(test)



mle_cox_PG <- constrOptim(test,neg_log_vrais,grad = NULL,ui=const,ci=c(0,0,0,-1,0,0,0),outer.eps = .Machine$double.eps)

mle_cox_PG



w(mle_cox_PG$par)

F_x_2_inv <- function(u,theta,lambda,alpha){
  (1-u)^(-1/alpha) * (theta+lambda) - lambda
}

F_X_inv <- function(u){
  if(u <= w(mle_cox_PG$par)){
    Fx1_inv (u * FF(mle_cox_PG$par) / w(mle_cox_PG$par) , mle_cox_PG$par[1],mle_cox_PG$par[2],mle_cox_PG$par[3])
  }else{
    F_x_2_inv((u-w(mle_cox_PG$par)) / (1-w(mle_cox_PG$par)),mle_cox_PG$par[4],mle_cox_PG$par[5],mle_cox_PG$par[6])
  }
}
F_d <- w(mle_cox_PG$par)* Fx1(500,mle_cox_PG$par[1],mle_cox_PG$par[2],mle_cox_PG$par[3])/FF(mle_cox_PG$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_cox_PG$par[4],col=3)
title("QQPlot Coxienne2 - Pareto g?n?ralis? cont.")
t1 <- mle_cox_PG$par[4]
#Test d'ad?quation graphique de la premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto g?n?ralis? cont.")


f_X <- function(x){
  if(x<=t1){
    w(mle_cox_PG$par)/FF(mle_cox_PG$par) * fx1(x,mle_cox_PG$par[1],mle_cox_PG$par[2],mle_cox_PG$par[3])
  }else{
    (1-w(mle_cox_PG$par))  * f_2(x,mle_cox_PG$par)
  }
}

#V?rification de la ontinuit?
x <- seq(t1-20,t1+20,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)


F_2 <- function(x,para){
  1- ((para[1]+para[4])/(x+para[4]))^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * Fx1(x,mle_cox_PG$par[1],mle_cox_PG$par[2],mle_cox_PG$par[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

FFF <- function(x){
  (sapply(x,F_X,para=mle_cox_PG$par)-F_d)/(1-F_d)
}
#Test d'Anderson-Darling
(AD_cox_PG<- goftest::ad.test(LOSS,FFF))
#Calcule du AIC et BSC
AIC_cox_PG<- 2 * 6 + 2* mle_cox_PG$value
BSC_cox_PG <- 6 * log(length(LOSS)) + 2*mle_cox_PG$value

# 1.3.14.COXIENNE 2-Pareto G?n?ralis?e choix du t1 --------------------------------------------------
#On choisit le point de coupure t1
t1 <- b_ord[9100]
w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- norwegianfire$size
b_ord <- LOSS[order(LOSS)]
MeanExcess(norwegianfire$size, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)

LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_GP <- sort(LOSS[LOSS>t1])

F_1 <- function(x,para){
  Fx1(x,para[1],para[2],para[3])
}

f_2 <- function(x,para){
  (para[1]+t1)^(para[2]) * para[2] / (para[1]+x)^(para[2]+1)
}


f_1 <- function(x,para){
  fx1(x,para[1],para[2],para[3])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(500,para))
}
neg_log_vrais_PG <- function(para){
  -sum(sapply(LOSS_GP,function(l) log(f_2(l,para))))
}


mle_MD_cox <-  constrOptim(c(1/500,1/1000,0.5),neg_log_vrais_MD,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)
mle_GP <- constrOptim(c(1,1),neg_log_vrais_PG,grad = NULL,ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)
#Mle de la coxienne2
mle_MD_cox
#Mle de la PG
mle_GP

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-((para[3]+t1)/(para[3]+x))^(para[4]))
  }  
}


F_x_2_inv <- function(u,lambda,theta,alpha){
  (1-u)^(-1/alpha) * (theta+lambda) -lambda
}

F_X_inv <- function(u){
  if(u <= w1){
    Fx1_inv(u * (F_1(t1,mle_MD_cox$par)-F_1(500,mle_MD_cox$par))/ w1 + F_1(500,mle_MD_cox$par) ,mle_MD_cox$par[1],mle_MD_cox$par[2],mle_MD_cox$par[3])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_GP$par[1],t1,mle_GP$par[2])
  }  
}
F_d <- w1* F_1(500,mle_MD_cox$par)/ F_1(t1,mle_MD_cox$par)
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto g?n?ralis?e")
#Test d'ad?quation graphique de la partie coxienne2
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+100
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto g?n?ralis?e")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_cox$par)-F_1(500,mle_MD_cox$par)) * f_1(x,mle_MD_cox$par)
  }else{
    (1-w1) * f_2(x,mle_GP$par)
  }
}
#V?rification de la discontinuit?
x <- seq(t1-50,t1+50,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

F_2 <- function(x,para){
  1- ((para[1]+t1)/(x+t1))^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    w1 / (F_1(t1,mle_MD_cox$par)-F_1(500,mle_MD_cox$par)) * (F_1(x,mle_MD_cox$par)-F_1(500,mle_MD_cox$par))
  }else{
    w1 + (1-w1) * F_2(x,mle_GP$par)
  }
}

F_d <- F_X(500)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
#Test d'Anderon-Darling
(AD_cox_PG_2<- goftest::ad.test(LOSS,FFF))

AIC_cox_PG_2<- 2 * 5 - 2* sum(log(sapply(LOSS,f_X)))
BSC_cox_PG_2 <- 5 * log(length(LOSS)) - 2*sum(log(sapply(LOSS,f_X)))

# 1.3.15.Comparaison des r?sultats ----------------------------------------
#Avec AIC et BSC

Model <- c("LN-Pa","LN-Pa theta fix?","LN-PG","LN-PG theta fix?","LN-Pa-Pa","Weibull-Pa","Weibull-Pa theta fix?","Weibull-PG","Weibull-Pa theta fix?","Weibull-Pa-Pa","Cox2-Pa","Cox2-Pa theta fix?","Cox2-PG","Cox2-PG theta fix?")
AIC <- c(AIC_LN_pa,AIC_LN_pa_2,AIC_LN_PG,AIC_LN_PG_2,AIC_LN_pa_pa,AIC_Wei_pa,AIC_Wei_pa_2,AIC_Wei_PG,AIC_Wei_PG_2,AIC_Wei_pa_pa,AIC_cox_pa,AIC_cox_pa_2,AIC_cox_PG,AIC_cox_PG_2)
BSC <- c(BSC_LN_pa,BSC_LN_pa_2,BSC_LN_PG,BSC_LN_PG_2,BSC_LN_pa_pa,BSC_Wei_pa,BSC_Wei_pa_2,BSC_Wei_PG,BSC_Wei_PG_2,BSC_Wei_pa_pa,BSC_cox_pa,BSC_cox_pa_2,BSC_cox_PG,BSC_cox_PG_2)
AD_STAT <-  c(AD_LN_Pa$statistic,AD_LN_Pa_2$statistic,AD_LN_PG$statistic,AD_LN_PG_2$statistic,AD_LN_Pa_Pa$statistic,AD_Wei_Pa$statistic,AD_Wei_Pa_2$statistic,AD_Wei_PG$statistic,AD_Wei_PG_2$statistic,AD_Wei_Pa_Pa$statistic,AD_cox_pa$statistic,AD_cox_pa_2$statistic,AD_cox_PG$statistic,AD_cox_PG_2$statistic) 
AD_p <- c(AD_LN_Pa$p.value,AD_LN_Pa_2$p.value,AD_LN_PG$p.value,AD_LN_PG_2$p.value,AD_LN_Pa_Pa$p.value,AD_Wei_Pa$p.value,AD_Wei_Pa_2$p.value,AD_Wei_PG$p.value,AD_Wei_PG_2$p.value,AD_Wei_Pa_Pa$p.value,AD_cox_pa$p.value,AD_cox_pa_2$p.value,AD_cox_PG$p.value,AD_cox_PG_2$p.value)

choix <- cbind(1:14,AIC,BSC,AD_STAT,AD_p)
result <- data.frame("Mod?le-S?v?rit? Norwegian Fire"=Model,AIC,BSC,AD_STAT,AD_p)
result
(choix_AIC <- choix[order(AIC),])
(choix_BSC <- choix[order(BSC),])

result[6,]
result[10,]
result[8,]

R <- 2*(LOG_VRAIS_Wei_pa_pa-LOG_VRAIS_Wei_pa)
qchisq(0.95,1)
qchisq(0.9,1)
#On choisit la Weibull-Pareto simple


# 1.4.Aggregation ---------------------------------------------------------
## ModÃ¨le de sÃ©vÃ©ritÃ© retenu : Splicing d'une Weibull avec une Pareto
## ModÃ¨le de frÃ©quence retenu : Processus homogÃ¨ne(657 sinistres par annÃ©e)
##
## AgrÃ©gation des risques : 
##
## On agrÃ¨ge les risque sur un an (365 jours)
##
## Algorithme d'agrÃ©gation

# 1.4.1.D?finition --------------------------------------------------------------


data("norwegianfire")
LOSS <- norwegianfire$size
b_ord <- sort(LOSS)
theta <- 1941.1048644
alpha <- 1.3245057
tau <- 0.5959684
para_mle <- c(theta,alpha,tau)


beta <- function(para){
  para[1] / (para[2]/para[3]+1)^(1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}

w <- function(para){
  (exp(para[2]/para[3]+1)-1) / (exp(para[2]/para[3]+1)+para[3]/para[2])
}
beta1 <- beta(para_mle)

w1 <- w(para_mle)
F1 <- FF(para_mle)

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv <- function(u){
  if(u <= w(para_mle)){
    qweibull(u * FF(para_mle) / w(para_mle) , para_mle[3],beta(para_mle))
  }else{
    F_x_2_inv((u-w(para_mle)) / (1-w(para_mle)),para_mle[2],para_mle[1])
  }
}
F_d <- w(para_mle)*pweibull(500,para_mle[3],beta(para_mle))/FF(para_mle)
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=para_mle[1],col=3)
title("QQPlot Weibull - Pareto cont. et d?riv.")

# 1.4.2.Agregation Weibull-Pareto -----------------------------------------------


set.seed(1734176512)
n <- 10^5

Lambda <- 622

rPP1 <- function(lam,F_inv){
  N <- rpois(1,lam)
  X <- sapply(runif(N)*(1-F_d)+F_d,F_inv)
  sum(X)
}
F_X_inv(F_d)
S <- replicate(n,rPP1(Lambda,F_X_inv))

summary(S)
## Validation
E_X1_tr <- function(d){
  beta1 * gamma(1+1/tau) *(1-pgamma(d^tau,1+1/tau,1/beta1^tau))
}
E_X2_tr <- function(d){
  alpha * theta^alpha * d^(1-alpha) / (alpha-1)
}
#Esperance theorique de la loi composite
(E_X <- 1/(1-F_d) * ( w1 / F1 * (E_X1_tr(500)-E_X1_tr(theta)) + (1-w1) * E_X2_tr(theta)))

data.frame(Esperance.theorique= Lambda*E_X,Esperance.empirique=mean(S))

# 1.4.3.Mesures de risque ----
S.sorted_NF <- sort(S)
VaR_ <- function(k) S.sorted_NF[floor(k*n)]
VaR_S <- c(VaR_(0.90),
           VaR_(0.95),
           VaR_(0.99),
           VaR_(0.999),
           VaR_(0.9999))

TVaR_ <- function(k) mean(S.sorted_NF[(floor(k*n+1)):n])
TVaR_S <- c(TVaR_(0.90),
            TVaR_(0.95),
            TVaR_(0.99),
            TVaR_(0.999),
            TVaR_(0.9999))

kappa <- c(0.9,0.95,0.99,0.999,0.9999)

data.frame("Kappa"=kappa,"VaR"=VaR_S,"TVaR"=TVaR_S)


sapply(unique(norwegianfire$year),function(i) sum(norwegianfire$size[norwegianfire$year==i]))
## En conclusion, On surestime souvent les c?ut totaux

# 2.Secura ------------------------------------------------------------------
data("secura")

summary(secura$size)
#nombre d observation par ann?e
m <- sapply(1988:2001,function(t){
  sum(secura$year==t)  
})
#Nombre Moyen annuel
mean(m)

t <- 1:14
#Graphique freq
plot(t,cumsum(m),ylab="Nombre cumulÃ©",main = "Fonction cumulative")
hist(secura$year,main = "")
title("Histogramme de la fr?quence des sinistres de 1988 ? 2000")
#Graphique Sev
MeanExcess(secura$size, k=FALSE,main = "")
title("Fonction d'exc?s moyen")

hist(secura$size)
title("Histogramme du montant des r?clamations")
ExpQQ(secura$size)
ParetoQQ(secura$size)
# 2.1.Analyse Frequence -------------------------------------------------------
#Processus de Poisson - Homog?ne
t <- 1:14
#Le mle d'un PPH est la moyenne empirique
mle_homo <- mean(m)
mle_homo
#On calcule le log de la vraisemblance pour faire un teste de ratio
l_vrais_homo <- sum(log(dpois(m,mle_homo)))

#Processus de Poisson - Nonhomog?ne - Intensit? lin?aire
neg_log_vrais <- function(para){
  -sum(log(dpois(m,para[1] + para[2] * (2*(t-1)+1) / 2)))
}

mle_nonhomo <- constrOptim(c(24, 1), neg_log_vrais, grad = NULL, 
                           ui = c(1,0), ci = 0,outer.eps = .Machine$double.eps)
#Mle du PPNH
mle_nonhomo$par

#test visuel d'ad?quation avec la fr?quence cumul?e
plot(t,cumsum(m))
lines(t,mle_nonhomo$par[1]*(t) + mle_nonhomo$par[2]*(t)^2 / 2,col='red')
lines(t, mean(m)*(t),col='green')
# le PPH(vert) et PPNH(rouge) sont similaires

#V?rification si N(t)/t tends vers la moyenne (Test pour PP)
plot(t,cumsum(m)/(t),type = "l",ylab = "N(t)/t",xlab="t")
lines(t,rep(mean(m),length(t)),col='red')
#On n'a pas assez de donn?es pour tirer une conculsion

#Test de ratio de vraisemblance
R <- 2*(-mle_nonhomo$value-l_vrais_homo)
qchisq(0.95,1)
1-pchisq(R,1)
#On ne rejette H0 (PPH) --> on choisit le mod?le PPH

#Processus de Poisson - Nonhomog?ne - Intensit? exponentielle

intensite <- function(t,para){
  (para[1] * t)^para[2]
}

neg_log_vrais <- function(para){
  -sum(log(dpois(m,intensite(t,para)-intensite(t-1,para))))
}

mle_nonhomo_wei <- constrOptim(c(10, 1), neg_log_vrais, grad = NULL, 
                               ui = c(1,0), ci = 0,outer.eps = .Machine$double.eps)
#Mle PPNH (expo)
mle_nonhomo_wei$par

#test visuel d'ad?quation avec la fr?quence cumul?e
plot(t,cumsum(m))
lines(t,intensite(t,mle_nonhomo_wei$par),col='blue')
lines(t,mle_nonhomo$par[1]*(t) + mle_nonhomo$par[2]*(t)^2 / 2,col='red')
lines(t, mean(m)*(t),col='green')
# le PPH expo(bleu) n'est pas mieux que les autres

#Processus de Poisson - Nonhomog?ne - Intensit? saisonni?re (cosinus)

intensite_cos <- function(t,para){
  para[1] * t - para[2] * sin(2 *pi *t /para[3])
}


neg_log_vrais <- function(para){
  -sum(log(dpois(m,intensite_cos(t,para)-intensite_cos(t-1,para))))
}
#V?rification pour trouver des bonnes valeurs de d?part
y <- sapply(seq(0,20,by=0.01),intensite_cos,para=c(20,10,8))
plot(seq(0,20,by=0.01),y,type='l')


mle_nonhomo_cos <- constrOptim(c(20,10,8), neg_log_vrais, grad = NULL, 
                               ui = diag(3), ci = c(0,0,0),outer.eps = .Machine$double.eps)
#Mle du PPNH avec cos comme intensit?
mle_nonhomo_cos$par

#Intensit? cumul?e sur 20 ans (cycle sur 8 ans)
y <- sapply(seq(0,20,by=0.01),intensite_cos,para=mle_nonhomo_cos$par)
plot(seq(0,20,by=0.01),y,type='l')

#test visuel d'ad?quation avec la fr?quence cumul?e
plot(t,cumsum(m),ylab="Nombre cumulÃ©",main="Fonction cumulative")
lines(t,intensite_cos(t,mle_nonhomo_cos$par),col='blue')
lines(t, mean(m)*(t),col='green')
#le PPNH semble plus ad?quate

#Intensit? cumul?e sur 60 ans (cycle sur 8 ans)
plot(0:60,intensite_cos(0:60,mle_nonhomo_cos$par),type='l') 
#Bonne pr?diction pour le future? Ces cycles sont r?alistes?

#test de ratio de vraisemblance
(R <- 2*(-mle_nonhomo_cos$value-l_vrais_homo))
qchisq(0.95,2)
1-pchisq(R,2)
#On rejette H0 --> On choisit PPNH

AIC_PPH <- 2 * 4- 2* l_vrais_homo
BSC_PPH <- 4 * log(length(m)) - 2* l_vrais_homo
AIC_PPNH_cos <- 2 * 4- 2* -mle_nonhomo_cos$value
BSC_PPNH_cos <- 4 * log(length(m)) - 2* -mle_nonhomo_cos$value
#Avec BSC et AIC on choisit aussi le PPNH, m?me avec les 2 param?tres suppl?mentaires 

# 2.2.Analyse severite univariee ------------------------------------------

#Fonction de r?partition empirique
F_B <- function(x){
  sum(b<=x)/length(b)
}

# 2.2.1.Loi Exponentielle

b <- secura$size
plot(ecdf(b))

b <- b/1000000
(b_ord <- b[order(b)])


mean(b)

neg_log_vrais <- function(x){
  -sum(log(dexp(b,x)/(1-pexp(1.2,x))))
}
#V?rification du mle
1/(lambda <- optimize(neg_log_vrais,c(0.6,5))$minimum)+1.2

#V?rification graphique
F_d <- pexp(1.2,lambda)
p <- sapply(b_ord,function(x){F_B(x)})
p <- p+(1-p)*F_d
plot(b_ord,qexp(p, (lambda)),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (expo)")
lines(b_ord,b_ord,col='red')

# 2.2.2. Loi Pareto (2 param?tres)
neg_log_vrais <- function(para){
  -sum(log(dpareto(b,para[1],para[2])/(1-ppareto(1.2,para[1],para[2]))))
}

mle_pareto <- constrOptim(c(1.8, 0.7), neg_log_vrais, grad = NULL, 
                          ui = diag(2), ci = c(0, 0))
mean(b)
mle_pareto

p <- sapply(b_ord,function(x){F_B(x)})
p <- p + (1-p) * ppareto(1.2, mle_pareto$par[1], mle_pareto$par[2])
plot(b_ord,qpareto(p, mle_pareto$par[1], mle_pareto$par[2]),xlab="Quantiles observes",ylab="Quantiles theoriques (pareto)")
lines(b_ord,b_ord,col='red')

# 2.2.3. Loi gamma

neg_log_vrais <- function(para){
  -sum(log(dgamma(b,para[1],para[2])/pgamma(1.2,para[1],para[2],lower.tail = FALSE)))
}

mle_gamma <- constrOptim(c(4, 1/4), neg_log_vrais, grad = NULL, 
                         ui = diag(2), ci = c(0,0))
mle_gamma$par

mle_gamma$par[1]/mle_gamma$par[2]
mean(b)

p <- sapply(b_ord,function(x){F_B(x)})
p <- p + (1-p) * pgamma(1.2,  mle_gamma$par[1], mle_gamma$par[2])
plot(b_ord,qgamma(p, mle_gamma$par[1], mle_gamma$par[2]),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (pareto)")
lines(b_ord,b_ord,col='red')

# 2.2.4. Loi log normal
neg_log_vrais <- function(para){
  -sum(log(dlnorm(b,para[1],para[2])/plnorm(1.2,para[1],para[2],lower.tail=FALSE)))
}


mle_lnorm <- constrOptim(c(1, 1), neg_log_vrais, grad = NULL, 
                         ui = c(0,1), ci = 0)
mle_lnorm

exp(mle_lnorm$par[1]+mle_lnorm$par[2]^2/2)

p <- sapply(b_ord,function(x){F_B(x)})
p <- p + (1-p)* plnorm(p, mle_lnorm$par[1], mle_lnorm$par[2])
plot(b_ord,qlnorm(p, mle_lnorm$par[1], mle_lnorm$par[2]),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (log norm)")
lines(b_ord,b_ord,col='red')

# 2.3.Analyse severite splicing -------------------------------------------
# 2.3.1.LN-Pareto (continue & d?rivable) ------------------------------------------------------------------


LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]

mu <- function(para){
  log(para[1]) - para[2] * para[3]^2
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}

w <- function(para){
  FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]^2*para[3]^2/2) / (1+FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]^2*para[3]^2/2))
}


f_1 <- function(x,para){
  dlnorm(x,mu(para),para[3])
}
f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* plnorm(1.2,mu(para),para[3])/FF(para))
}

mle_LN_pa <- constrOptim(c(3,1.29,0.82),neg_log_vrais,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)

mle_LN_pa

mu(mle_LN_pa$par)

w(mle_LN_pa$par)

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv <- function(u){
  if(u <= w(mle_LN_pa$par)){
    qlnorm(u * FF(mle_LN_pa$par) / w(mle_LN_pa$par) , mu(mle_LN_pa$par), mle_LN_pa$par[3])
  }else{
    F_x_2_inv((u-w(mle_LN_pa$par)) / (1-w(mle_LN_pa$par)),mle_LN_pa$par[2],mle_LN_pa$par[1])
  }
}
F_d <- w(mle_LN_pa$par)*plnorm(1.2,mu(mle_LN_pa$par),mle_LN_pa$par[3])/FF(mle_LN_pa$par)
t1 <- mle_LN_pa$par[1]
#Test d'ad?quation graphique support complet
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (log norm - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_LN_pa$par[1],col=3)
title("QQPlot LN-Pa cont. et d?riv.")
#Test d'ad?quation graphique premi?re partie
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
p <- p+F_d * (1-p)
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (log norm - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa cont. et d?riv.")
F_B(t1)


F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * plnorm(x,mu(para),para[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}


FFF <- function(x){
  (sapply(x,F_X,para=mle_LN_pa$par)-F_d)/(1-F_d)
}
AD_LN_Pa <- goftest::ad.test(LOSS,FFF)

AIC_LN_pa <- 2 * length(mle_LN_pa$par) + 2* mle_LN_pa$value 
BSC_LN_pa <- length(mle_LN_pa$par) * log(length(LOSS)) + 2 * mle_LN_pa$value
LOG_VRAIS_LN_Pa <- -mle_LN_pa$value
# 2.3.2.LN-Pareto choix du t1  ------------------------------------------------------


LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]


w1 <- 0.87


t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

MeanExcess(secura$size/1000000, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)





LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA1 <- sort(LOSS[LOSS>t1])


F_1 <- function(x,para){
  plnorm(x,para[1],para[2])
}

f_2 <- function(x,para){
  t1^para * para / x^(para+1)
}


f_1 <- function(x,para){
  dlnorm(x,para[1],para[2])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(1.2,para))
}
neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA1,function(l) log(f_2(l,para))))
}


mle_MD_LN <-  constrOptim(c(6,1),neg_log_vrais_MD,grad = NULL,ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)
mle_pa1_LN <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum

mle_MD_LN
mle_pa1_LN


F_x_2_inv <- function(u,theta,alpha){
  (1-u)^(-1/alpha) * theta
}

F_X_inv <- function(u){
  if(u <= w1){
    qlnorm(u * (F_1(t1,mle_MD_LN$par)-F_1(1.2,mle_MD_LN$par))/ w1 + F_1(1.2,mle_MD_LN$par) ,mle_MD_LN$par[1],mle_MD_LN$par[2])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,t1,mle_pa1_LN)
  }  
}
F_d <- w1* F_1(1.2,mle_MD_LN$par)/ F_1(t1,mle_MD_LN$par)

n <- length(LOSS)
p <- (1:n)/(n+1)

plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa")

n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_LN$par)-F_1(1.2,mle_MD_LN$par)) * f_1(x,mle_MD_LN$par)
  }else{
    (1-w1) * f_2(x,mle_pa1_LN)
  }
}

x <- seq(1,10,by=0.001)
plot(x,sapply(x,f_X),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-0.1,t1+0.1,by=0.001)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)


F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    (F_1(x,mle_MD_LN$par)-F_1(1.2,mle_MD_LN$par)) * w1 / (F_1(t1,mle_MD_LN$par)-F_1(1.2,mle_MD_LN$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_LN))
  }
}
F_X(1.3)

F_d <- F_X(1.2)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
(AD_LN_Pa_2 <- goftest::ad.test(LOSS,FFF))

AIC_LN_pa_2 <- 2 * 3 - 2* sum(log(sapply(LOSS,f_X)))
BSC_LN_pa_2 <- 3 * log(length(LOSS)) - 2 *  sum(log(sapply(LOSS,f_X)))

# 2.3.3.LN-Pareto G?n?ralis?e (continue & d?rivable) -------------------------------------------------------------



LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]

mu <- function(para){
  (log(para[1]) - para[2]*para[1] * para[3]^2 / (para[4]+para[1])) / (1 - para[3]^2 / (para[4]+para[1]))
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}

w <- function(para){
  FF(para) * para[1] * para[2] * para[3] * sqrt(2*pi) * exp( (log(para[1])-mu(para))^2 / (2*para[3]^2 )) / (para[1]+para[4]+FF(para) * para[1] * para[2] * para[3] * sqrt(2*pi) * exp( (log(para[1])-mu(para))^2 / (2*para[3]^2 )))
}


f_1 <- function(x,para){
  dlnorm(x,mu(para),para[3])
}
f_2 <- function(x,para){
  para[2] * (para[1]+para[4])^para[2] / (para[4]+x)^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* plnorm(1.2,mu(para),para[3])/FF(para))
}




mle_LN_PG <- constrOptim(c(3,1.32,1.14,1),neg_log_vrais,grad = NULL,ui=matrix(c(1,0,0,0,1,0,0,0,1,0,0,0),3,4),ci=c(0,0,0),outer.eps = .Machine$double.eps)


mle_LN_PG

FF(mle_LN_PG$par)

w(mle_LN_PG$par)

F_x_2_inv <- function(u,alpha,theta,lambda){
  (1-u)^(-1/alpha) * (theta+lambda) - lambda
}
F_X_inv <- function(u){
  if(u <= w(mle_LN_PG$par)){
    qlnorm(u * FF(mle_LN_PG$par) / w(mle_LN_PG$par) , mu(mle_LN_PG$par), mle_LN_PG$par[3])
  }else{
    F_x_2_inv((u-w(mle_LN_PG$par)) / (1-w(mle_LN_PG$par)),mle_LN_PG$par[2],mle_LN_PG$par[1],mle_LN_PG$par[4])
  }
}
F_d <- w(mle_LN_PG$par)*plnorm(1.2,mu(mle_LN_PG$par),mle_LN_PG$par[3])/FF(mle_LN_PG$par)

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_LN_PG$par[1],col=3)
title("QQPlot LN-PG cont. et d?riv.")
t1 <- mle_LN_PG$par[1]
n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
p <- p+F_d * (1-p)
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-PG cont. et d?riv.")
F_B(t1)


F_2 <- function(x,para){
  1- ((para[1]+para[4])/(x+para[4]))^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * plnorm(x,mu(para),para[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

F_2 <- function(x,para){
  1- ((para[1]+para[4])/(x+para[4]))^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * plnorm(x,mu(para),para[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}


F_d <- FFF(1.2)
FFF <- function(x){
  (sapply(x,F_X,para=mle_LN_PG$par)-F_d)/(1-F_d)
}
(AD_LN_PG <- goftest::ad.test(LOSS,FFF))
AIC_LN_PG <- 2 * length(mle_LN_PG$par) + 2* mle_LN_PG$value 
BSC_LN_PG <- length(mle_LN_PG$par) * log(length(LOSS)) + 2 * mle_LN_PG$value
LOG_VRAIS_LN_PG <- -mle_LN_PG$value
# 2.3.4.LN-Pareto G?n?ralis?e choix du t1 -----------------------------------------------




LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]


w1 <- 0.87


t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

MeanExcess(secura$size/1000000, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)




LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_GP <- sort(LOSS[LOSS>t1])


F_1 <- function(x,para){
  plnorm(x,para[1],para[2])
}

f_2 <- function(x,para){
  (para[1]+t1)^(para[2]) * para[2] / (para[1]+x)^(para[2]+1)
}


f_1 <- function(x,para){
  dlnorm(x,para[1],para[2])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(1.2,para))
}
neg_log_vrais_PG <- function(para){
  -sum(sapply(LOSS_GP,function(l) log(f_2(l,para))))
}


mle_MD_LN <-  constrOptim(c(6,1),neg_log_vrais_MD,grad = NULL,ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)
mle_GP <- constrOptim(c(1,1),neg_log_vrais_PG,grad = NULL,ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)

mle_MD_LN
mle_GP

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-((para[3]+t1)/(para[3]+x))^(para[4]))
  }  
}


F_x_2_inv <- function(u,lambda,theta,alpha){
  (1-u)^(-1/alpha) * (theta+lambda) -lambda
}

F_X_inv <- function(u){
  if(u <= w1){
    qlnorm(u * (F_1(t1,mle_MD_LN$par)-F_1(1.2,mle_MD_LN$par))/ w1 + F_1(1.2,mle_MD_LN$par) ,mle_MD_LN$par[1],mle_MD_LN$par[2])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_GP$par[1],t1,mle_GP$par[2])
  }  
}
F_d <- w1* F_1(1.2,mle_MD_LN$par)/ F_1(t1,mle_MD_LN$par)

n <- length(LOSS)
p <- (1:n)/(n+1)

plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-PG")

n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-PG")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_LN$par)-F_1(1.2,mle_MD_LN$par)) * f_1(x,mle_MD_LN$par)
  }else{
    (1-w1) * f_2(x,mle_GP$par)
  }
}

x <- seq(1,10,by=0.001)
plot(x,sapply(x,f_X),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-0.1,t1+0.1,by=0.001)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)


F_2 <- function(x,para){
  1- ((para[1]+t1)/(x+para[1]))^(para[2])
}
F_X <- function(x){
  if(x<= 1.2){
    0
  }
  else if( x <= t1){
    w1 / (F_1(t1,mle_MD_LN$par)-F_1(1.2,mle_MD_LN$par)) * (F_1(x,mle_MD_LN$par)-F_1(1.2,mle_MD_LN$par))
  }else{
    w1 + (1-w1) * F_2(x,mle_GP$par)
  }
}

F_d <- F_X(1.2)

FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
(AD_LN_PG_2 <- goftest::ad.test(LOSS,FFF))
AIC_LN_PG_2 <- 2 * 3 - 2* sum(log(sapply(LOSS,f_X)))
BSC_LN_PG_2 <- 3 * log(length(LOSS)) - 2 *  sum(log(sapply(LOSS,f_X)))

# 2.3.5.LN-Pareto-Pareto -----------------------------------------------------------




w1 <- 0.95


t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]
MeanExcess(secura$size/1000000, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)





LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA <- sort(LOSS[LOSS>t1])
mu <- function(para){
  log(para[1]) - para[2] * para[3]^2
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}

w <- function(para){
  FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]*para[3]^2/2) / (1+FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]*para[3]^2/2))
}


f_1 <- function(x,para){
  dlnorm(x,mu(para),para[3])
}
f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) * plnorm(x,mu(para),para[3])/FF(para)
  }
  else{
    w(para) + (1-w(para) ) * (1-(para[1]/x)^(para[2]))
  }  
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_X(l,para))))+length(LOSS_MD) * log(F_X(t1,para)-F_X(1.2,para))
}


mle_MD_LN_pa <- constrOptim(c(3,1.29,0.82),neg_log_vrais,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)


f_3 <- function(x,para){
  t1^para * para / x^(para+1)
}


neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA,function(l) log(f_3(l,para))))
}

mle_MD_LN_pa
mle_pa1_LN <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum
mle_pa1_LN

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv_1 <- function(u){
  if(u <= w(mle_MD_LN_pa$par)){
    qlnorm(u * FF(mle_MD_LN_pa$par)/ w(mle_MD_LN_pa$par), mu(mle_MD_LN_pa$par), mle_MD_LN_pa$par[3])
  }else{
    F_x_2_inv((u-w(mle_MD_LN_pa$par)) / (1-w(mle_MD_LN_pa$par)),mle_MD_LN_pa$par[2],mle_MD_LN_pa$par[1])
  }
}

F_X_inv <- function(u){
  if(u <= w1){
    F_X_inv_1(u/w1 * (F_X(t1,mle_MD_LN_pa$par)-F_X(1.2,mle_MD_LN_pa$par))+ F_X(1.2,mle_MD_LN_pa$par))
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_pa1_LN,t1)
  }  
}

n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - pareto - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_MD_LN_pa$par[1],col=3)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa-Pa")



n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (LN - pareto - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa-Pa")

F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
FF_X <- function(x){
  if(x <= t1){
    (F_X(x,mle_MD_LN_pa$par)-F_X(1.2,mle_MD_LN_pa$par)) * w1 / (F_X(t1,mle_MD_LN_pa$par)-F_X(1.2,mle_MD_LN_pa$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_LN))
  }
}

F_d <- FF_X(1.2)
FFF <- function(x){
  (sapply(x,FF_X)-F_d)/(1-F_d)
}
(AD_LN_Pa_Pa<- goftest::ad.test(LOSS,FFF))
ff_X <- function(x){
  if(x<=t1){
    w1/(F_X(t1,mle_MD_LN_pa$par)-F_X(1.2,mle_MD_LN_pa$par)) * f_X(x,mle_MD_LN_pa$par)
  }else{
    (1-w1) * f_3(x,mle_pa1_LN)
  } 
}

AIC_LN_pa_pa <- 2 * 4- 2* sum(log(sapply(LOSS,ff_X)))
BSC_LN_pa_pa <- 4 * log(length(LOSS)) - 2* sum(log(sapply(LOSS,ff_X)))


# 2.3.6.Weibull-Pareto (continue & d?rivable) -----------------------------------------------------------


LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]

beta <- function(para){
  para[1] / (para[2]/para[3]+1)^(1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}

pexp(1,2)
pweibull(1,1,0.5)

w <- function(para){
  (exp(para[2]/para[3]+1)-1) / (exp(para[2]/para[3]+1)+para[3]/para[2])
}


f_1 <- function(x,para){
  dweibull(x,para[3],beta(para))
}
f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* pweibull(1.2,para[3],beta(para))/FF(para))
}




mle_Wei_pa <- constrOptim(c(2,1.3242,0.59),neg_log_vrais,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)

mle_Wei_pa

mu(mle_Wei_pa$par)

w(mle_Wei_pa$par)

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv <- function(u){
  if(u <= w(mle_Wei_pa$par)){
    qweibull(u * FF(mle_Wei_pa$par) / w(mle_Wei_pa$par) , mle_Wei_pa$par[3],beta(mle_Wei_pa$par))
  }else{
    F_x_2_inv((u-w(mle_Wei_pa$par)) / (1-w(mle_Wei_pa$par)),mle_Wei_pa$par[2],mle_Wei_pa$par[1])
  }
}
F_d <- w(mle_Wei_pa$par)*pweibull(1.2,mle_Wei_pa$par[3],beta(mle_Wei_pa$par))/FF(mle_Wei_pa$par)
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_Wei_pa$par[1],col=3)
title("QQPlot Weibull - Pareto cont. et d?riv.")
t1 <- mle_Wei_pa$par[1]
x <- t1+0.1

plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto cont. et d?riv.")
F_B(t1)


F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * pweibull(x,para[3],beta(para))}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

FFF <- function(x){
  (sapply(x,F_X,para=mle_Wei_pa$par)-F_d)/(1-F_d)
}
(AD_Wei_Pa<- goftest::ad.test(LOSS,FFF))

AD_Wei_Pa <- AD_stat(LOSS,FFF,FFF_inv,F_d,1.2,1000)
AIC_Wei_pa <- 2 * 3 + 2* mle_Wei_pa$value
BSC_Wei_pa <- 3 * log(length(LOSS)) + 2*mle_Wei_pa$value
LOG_VRAIS_Wei_pa <- -mle_Wei_pa$value

# 2.3.7.Weibull-Pareto choix du t1  --------------------------------------------------------




LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]


w1 <- 0.87


t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

MeanExcess(secura$size/1000000, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)





LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA1 <- sort(LOSS[LOSS>t1])


F_1 <- function(x,para){
  pweibull(x,para[1],para[2])
}

f_2 <- function(x,para){
  t1^para * para / x^(para+1)
}


f_1 <- function(x,para){
  dweibull(x,para[1],para[2])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(1.2,para))
}
neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA1,function(l) log(f_2(l,para))))
}


mle_MD_Wei <-  constrOptim(c(1/2,1),neg_log_vrais_MD,grad = NULL,ui=diag(2),ci=c(0,0),outer.eps = .Machine$double.eps)
mle_pa1_Wei <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum

mle_MD_Wei
mle_pa1_Wei

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-(t1/x)^(para[3]))
  }  
}


F_x_2_inv <- function(u,theta,alpha){
  (1-u)^(-1/alpha) * theta
}

F_X_inv <- function(u){
  if(u <= w1){
    qweibull(u * (F_1(t1,mle_MD_Wei$par)-F_1(1.2,mle_MD_Wei$par))/ w1 + F_1(1.2,mle_MD_Wei$par) ,mle_MD_Wei$par[1],mle_MD_Wei$par[2])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,t1,mle_pa1_Wei)
  }  
}
F_d <- w1* F_1(1.2,mle_MD_Wei$par)/ F_1(t1,mle_MD_Wei$par)

n <- length(LOSS)
p <- (1:n)/(n+1)

plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - Pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto")

n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_Wei$par)-F_1(1.2,mle_MD_Wei$par)) * f_1(x,mle_MD_Wei$par)
  }else{
    (1-w1) * f_2(x,mle_pa1_Wei)
  }
}

F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    (F_1(x,mle_MD_Wei$par)-F_1(1.2,mle_MD_Wei$par)) * w1 / (F_1(t1,mle_MD_Wei$par)-F_1(1.2,mle_MD_Wei$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_Wei))
  }
}

F_d <- F_X(1.2)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
(AD_Wei_Pa_2<- goftest::ad.test(LOSS,FFF))

AIC_Wei_pa_2 <- 2 * 3 - 2* sum(log(sapply(LOSS,f_X)))
BSC_Wei_pa_2 <- 3 * log(length(LOSS)) - 2*sum(log(sapply(LOSS,f_X)))

# 2.3.8.Weibull-Pareto G?n?ralis?e (continue & d?rivable) --------------------------------------------------------

LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]

beta <- function(para){
  para[1] * ( (para[2] * para[1] -para[4])/ ((para[4]+para[1])*para[3]) + 1)^(-1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}

w <- function(para){
  (exp((para[1]/beta(para))^para[3])-1) / ( (para[3]/para[2]) * (para[4]/para[1]+1) * (para[1]/beta(para))^para[3] +  exp((para[1]/beta(para))^para[3])-1) 
}

f_1 <- function(x,para){
  dweibull(x,para[3],beta(para))
}
f_2 <- function(x,para){
  para[2] * (para[1]+para[4])^para[2] / (para[4]+x)^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* pweibull(1.2,para[3],beta(para))/FF(para))
}




mle_Wei_PG <- constrOptim(c(3,1.38,0.9,0),neg_log_vrais,grad = NULL,ui=matrix(c(1,0,0,0,1,0,0,0,1,0,0,0),3,4),ci=c(0,0,0),outer.eps = .Machine$double.eps)


mle_Wei_PG

mu(mle_Wei_PG$par)

w(mle_Wei_PG$par)

F_x_2_inv <- function(u,alpha,theta,lambda){
  (1-u)^(-1/alpha) * (theta+lambda) - lambda
}
F_X_inv <- function(u){
  if(u <= w(mle_Wei_PG$par)){
    qweibull(u * FF(mle_Wei_PG$par) / w(mle_Wei_PG$par) , mle_Wei_PG$par[3],beta(mle_Wei_PG$par))
  }else{
    F_x_2_inv((u-w(mle_Wei_PG$par)) / (1-w(mle_Wei_PG$par)),mle_Wei_PG$par[2],mle_Wei_PG$par[1],mle_Wei_PG$par[4])
  }
}
F_d <- w(mle_Wei_PG$par)*pweibull(1.2,mle_Wei_PG$par[3],beta(mle_Wei_PG$par))/FF(mle_Wei_PG$par)
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_Wei_PG$par[1],col=3)
title("QQPlot Weibull - PG cont. et d?riv.")

t1 <- mle_Wei_PG$par[1]
x <- t1+0.1

plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - PG cont. et d?riv.")
F_B(t1)

summary(LOSS)


F_2 <- function(x,para){
  1- ((para[1]+para[4])/(x+para[4]))^(para[2])
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) / FF(para) * pweibull(x,para[3],beta(para))}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

FFF <- function(x){
  (sapply(x,F_X,para=mle_Wei_PG$par)-F_d)/(1-F_d)
}
(AD_Wei_PG<- goftest::ad.test(LOSS,FFF))
AIC_Wei_PG <- 2 * 4 + 2* mle_Wei_PG$value
BSC_Wei_PG <- 4 * log(length(LOSS)) + 2*mle_Wei_PG$value

# 2.3.9.Weibull-Pareto G?n?ralis?e choix du t1 -----------------------------------------------


LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]


w1 <- 0.87

t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

MeanExcess(secura$size/1000000, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)

LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_GP <- sort(LOSS[LOSS>t1])


F_1 <- function(x,para){
  pweibull(x,para[1],para[2])
}

f_2 <- function(x,para){
  (para[1]+t1)^(para[2]) * para[2] / (para[1]+x)^(para[2]+1)
}


f_1 <- function(x,para){
  dweibull(x,para[1],para[2])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(1.2,para))
}
neg_log_vrais_PG <- function(para){
  -sum(sapply(LOSS_GP,function(l) log(f_2(l,para))))
}


mle_MD_Wei <-  constrOptim(c(1/2,1),neg_log_vrais_MD,grad = NULL,ui=diag(2),ci=c(0,0),outer.eps = .Machine$double.eps)
mle_GP <- constrOptim(c(1,1),neg_log_vrais_PG,grad = NULL,ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)

mle_MD_Wei
mle_GP

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-((para[3]+t1)/(para[3]+x))^(para[4]))
  }  
}


F_x_2_inv <- function(u,lambda,theta,alpha){
  (1-u)^(-1/alpha) * (theta+lambda) -lambda
}

F_X_inv <- function(u){
  if(u <= w1){
    qweibull(u * (F_1(t1,mle_MD_Wei$par)-F_1(1.2,mle_MD_Wei$par))/ w1 + F_1(1.2,mle_MD_Wei$par) ,mle_MD_Wei$par[1],mle_MD_Wei$par[2])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_GP$par[1],t1,mle_GP$par[2])
  }  
}
F_d <- w1* F_1(1.2,mle_MD_Wei$par)/ F_1(t1,mle_MD_Wei$par)

n <- length(LOSS)
p <- (1:n)/(n+1)

plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto g?n?ralsi?e")

n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Weibull - Pareto g?n?ralsi?e")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_Wei$par)-F_1(1.2,mle_MD_Wei$par)) * f_1(x,mle_MD_Wei$par)
  }else{
    (1-w1) * f_2(x,mle_GP$par)
  }
}

x <- seq(1,20,by=0.001)
plot(x,sapply(x,f_X),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-0.1,t1+0.1,by=0.001)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)


F_2 <- function(x,para){
  1- ((para[1]+t1)/(x+para[1]))^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    w1 / (F_1(t1,mle_MD_Wei$par)-F_1(1.2,mle_MD_Wei$par)) * (F_1(x,mle_MD_Wei$par)-F_1(1.2,mle_MD_Wei$par))
  }else{
    w1 + (1-w1) * F_2(x,mle_GP$par)
  }
}

F_d <- F_X(1.2)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
(AD_Wei_PG_2<- goftest::ad.test(LOSS,FFF))
AIC_Wei_PG_2 <- 2 * 4 - 2* sum(log(sapply(LOSS,f_X)))
BSC_Wei_PG_2 <- 4 * log(length(LOSS)) - 2*sum(log(sapply(LOSS,f_X)))

# 2.3.10.Weibull-Pareto-Pareto -----------------------------------------------------


w1 <- 0.95


t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]
MeanExcess(secura$size/1000000, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)


LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA <- sort(LOSS[LOSS>t1])
beta <- function(para){
  para[1] / (para[2]/para[3]+1)^(1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}

pexp(1,2)
pweibull(1,1,0.5)

w <- function(para){
  (exp(para[2]/para[3]+1)-1) / (exp(para[2]/para[3]+1)+para[3]/para[2])
}


f_1 <- function(x,para){
  dweibull(x,para[3],beta(para))
}


f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}
F_X <- function(x,para){
  if(x <= para[1]){
    w(para) * pweibull(x,para[3],beta(para))/FF(para)
  }
  else{
    w(para) + (1-w(para) ) * (1-(para[1]/x)^(para[2]))
  }  
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_X(l,para))))+length(LOSS_MD) * log(F_X(t1,para)-F_X(1.2,para))
}


mle_MD_Wei_pa <- constrOptim(c(3,1.29,0.82),neg_log_vrais,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)


f_3 <- function(x,para){
  t1^para * para / x^(para+1)
}


neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA,function(l) log(f_3(l,para))))
}

mle_MD_Wei_pa
mle_pa1_Wei <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum
mle_pa1_Wei

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv_1 <- function(u){
  if(u <= w(mle_MD_Wei_pa$par)){
    qweibull(u * FF(mle_MD_Wei_pa$par)/ w(mle_MD_Wei_pa$par),mle_MD_Wei_pa$par[3],beta(mle_MD_Wei_pa$par))
  }else{
    F_x_2_inv((u-w(mle_MD_Wei_pa$par)) / (1-w(mle_MD_Wei_pa$par)),mle_MD_Wei_pa$par[2],mle_MD_Wei_pa$par[1])
  }
}

F_X_inv <- function(u){
  if(u <= w1){
    F_X_inv_1(u/w1 * (F_X(t1,mle_MD_Wei_pa$par)-F_X(1.2,mle_MD_Wei_pa$par))+ F_X(1.2,mle_MD_Wei_pa$par))
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_pa1_Wei,t1)
  }  
}

n <- length(LOSS)
p <- (1:n)/(n+1)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - pareto - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_MD_Wei_pa$par[1],col=3)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot WeibullPa-Pa")



n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Weibull - pareto - pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot WeibullPa-Pa")

F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
FF_X <- function(x){
  if(x <= t1){
    (F_X(x,mle_MD_Wei_pa$par)-F_X(1.2,mle_MD_Wei_pa$par)) * w1 / (F_X(t1,mle_MD_Wei_pa$par)-F_X(1.2,mle_MD_Wei_pa$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_Wei))
  }
}


p_obs <- sapply(b_ord,function(x){F_B(x)})
p_theo <- sapply(b_ord,function(x){ FF_X(x)})
stats::ks.test(p_obs,p_theo)

F_d <- FF_X(1.2)
FFF <- function(x){
  (sapply(x,FF_X)-F_d)/(1-F_d)
}
(AD_Wei_Pa_Pa<- goftest::ad.test(LOSS,FFF))
ff_X <- function(x){
  if(x<=t1){
    w1/(F_X(t1,mle_MD_Wei_pa$par)-F_X(1.2,mle_MD_Wei_pa$par)) * f_X(x,mle_MD_Wei_pa$par)
  }else{
    (1-w1) * f_3(x,mle_pa1_Wei)
  } 
}


AIC_Wei_pa_pa <- 2 * 4- 2* sum(log(sapply(LOSS,ff_X)))
BSC_Wei_pa_pa <- 4 * log(length(LOSS)) - 2* sum(log(sapply(LOSS,ff_X)))

LOG_VRAIS_Wei_pa_pa <- sum(log(sapply(LOSS,ff_X)))

# COXIENNE2---------------------------------------------------------


# fonctions de la loi cox2
fx1 <- function(x,beta1,beta2,p){
  p * beta1*exp(-beta1*x) + (1-p)*(beta1*beta2)* ( exp(-beta1*x)/(beta2-beta1) + exp(-beta2*x)/(beta1-beta2) )
}

fx1_d <- function(x,beta1,beta2,p){
  -p * beta1^2*exp(-beta1*x) + (1-p)*beta1*beta2* ( - beta1 * exp(-beta1*x)/(beta2-beta1) - beta2 *exp(-beta2*x)/(beta1-beta2) )
}


Fx1 <- function(x,beta1,beta2,p){
  p * (1-exp(-beta1*x)) + (1-p) * ( beta2 * (1-exp(-beta1*x))/(beta2-beta1) + beta1 *(1-exp(-beta2*x))/(beta1-beta2)
  )}

Fx1_inv <- function(k,beta1,beta2,p){ 
  uniroot(function(x) Fx1(x,beta1,beta2,p) - k, c(0,10^9))$root
}


# 2.3.11.COXIENNE 2-Pareto (continue) ----------------------------------------------------


LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]


FF <- function(para){
  Fx1(para[4],para[1],para[2],para[3])
}


w <- function(para){
  FF(para) / ( FF(para) + para[4]/para[5] * fx1(para[4],para[1],para[2],para[3]))
}


f_2 <- function(x,para){
  para[5] * para[4]^para[5] * x^(-para[5]-1)
}

f_X <- function(x,para){
  if(x<=para[4]){
    w(para)/FF(para) * fx1(x,para[1],para[2],para[3])
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* Fx1(1.2,para[1],para[2],para[3])/FF(para))
}

const <- matrix(c(1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,1,0,0,0,0,0,0,1),6,5)
test <- c(0.5,0.3,0.5,3,1.28)

mle_cox_pa <- constrOptim(test,neg_log_vrais,grad = NULL,ui=const,ci=c(0,0,0,-1,0,0),outer.eps = .Machine$double.eps)

mle_cox_pa



w(mle_cox_pa$par)

F_x_2_inv <- function(u,theta,alpha){
  theta * (1-u)^(-1/alpha)
}


F_X_inv <- function(u){
  if(u <= w(mle_cox_pa$par)){
    Fx1_inv (u * FF(mle_cox_pa$par) / w(mle_cox_pa$par) , mle_cox_pa$par[1],mle_cox_pa$par[2],mle_cox_pa$par[3])
  }else{
    F_x_2_inv((u-w(mle_cox_pa$par)) / (1-w(mle_cox_pa$par)),mle_cox_pa$par[4],mle_cox_pa$par[5])
  }
}
F_d <- w(mle_cox_pa$par)* Fx1(1.2,mle_cox_pa$par[1],mle_cox_pa$par[2],mle_cox_pa$par[3])/FF(mle_cox_pa$par)

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - Pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_cox_pa$par[4],col=3)
title("QQPlot Coxienne2 - Pareto cont.")
t1 <- mle_cox_pa$par[4]

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - Pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto cont.")


F_2 <- function(x,para){
  1- (para[4]/x)^(para[5])
}
F_X <- function(x,para){
  if(x <= para[4]){
    w(para) / FF(para) * Fx1(x,para[1],para[2],para[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}


FFF <- function(x){
  (sapply(x,F_X,para=mle_cox_pa$par)-F_d)/(1-F_d)
}
(AD_cox_pa<- goftest::ad.test(LOSS,FFF))
AIC_cox_pa<- 2 * 5 + 2* mle_cox_pa$value
BSC_cox_pa <- 5 * log(length(LOSS)) + 2*mle_cox_pa$value

# 2.3.12.COXIENNE 2-Pareto choix du t1 -----------------------------------------------





w1 <- 0.95


t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]
MeanExcess(secura$size/1000000, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)


LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_PA1 <- sort(LOSS[LOSS>t1])


F_1 <- function(x,para){
  Fx1(x,para[1],para[2],para[3])
}

f_2 <- function(x,para){
  t1^para * para / x^(para+1)
}


f_1 <- function(x,para){
  fx1(x,para[1],para[2],para[3])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(1.2,para))
}
neg_log_vrais_pareto1 <- function(para){
  -sum(sapply(LOSS_PA1,function(l) log(f_2(l,para))))
}


mle_MD_cox <-  constrOptim(c(9.345379e-01, 8.252604e-09, 7.577125e-01),neg_log_vrais_MD,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)
mle_pa1_cox <- optimise(neg_log_vrais_pareto1,c(0,4))$minimum

mle_MD_cox
mle_pa1_cox

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-(t1/x)^(para[3]))
  }  
}


F_x_2_inv <- function(u,theta,alpha){
  (1-u)^(-1/alpha) * theta
}

F_X_inv <- function(u){
  if(u <= w1){
    Fx1_inv(u * (F_1(t1,mle_MD_cox$par)-F_1(1.2,mle_MD_cox$par))/ w1 + F_1(1.2,mle_MD_cox$par) ,mle_MD_cox$par[1],mle_MD_cox$par[2],mle_MD_cox$par[3])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,t1,mle_pa1_cox)
  }  
}
F_d <- w1* F_1(1.2,mle_MD_cox$par)/ F_1(t1,mle_MD_cox$par)

n <- length(LOSS)
p <- (1:n)/(n+1)

plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - Pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto")

n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - Pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_cox$par)-F_1(1.2,mle_MD_cox$par)) * f_1(x,mle_MD_cox$par)
  }else{
    (1-w1) * f_2(x,mle_pa1_cox)
  }
}

x <- seq(1,20000,by=1)
plot(x,sapply(x,f_X),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-20,t1+20,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)



F_2 <- function(x,para){
  1- (para[1]/x)^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    (F_1(x,mle_MD_cox$par)-F_1(1.2,mle_MD_cox$par)) * w1 / (F_1(t1,mle_MD_cox$par)-F_1(1.2,mle_MD_cox$par)) 
  }else{
    w1 + (1-w1) * F_2(x,c(t1,mle_pa1_cox))
  }
}

F_d <- F_X(1.2)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
(AD_cox_pa_2<- goftest::ad.test(LOSS,FFF))
AIC_cox_pa_2<- 2 * 4 - 2* sum(log(sapply(LOSS,f_X)))
BSC_cox_pa_2 <- 4 * log(length(LOSS)) - 2*sum(log(sapply(LOSS,f_X)))

# 2.3.13.COXIENNE 2-Pareto G?n?ralis?e (continue) ------------------------------------------------------


LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]


FF <- function(para){
  Fx1(para[4],para[1],para[2],para[3])
}


w <- function(para){
  FF(para) / ( FF(para) + (para[4]+para[5])/para[6] * fx1(para[4],para[1],para[2],para[3]))
}


f_2 <- function(x,para){
  para[6] * (para[4]+para[5])^para[6] / (x+para[5])^(para[6]+1)
}

f_X <- function(x,para){
  if(x<=para[4]){
    w(para)/FF(para) * fx1(x,para[1],para[2],para[3])
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* Fx1(1.2,para[1],para[2],para[3])/FF(para))
}


const <- matrix(c(1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1),7,6)
test <- c(0.5,0.3,0.7,2,1,1)

#1/1.2, 1/60,0.5,4000
w(test)



mle_cox_PG <- constrOptim(test,neg_log_vrais,grad = NULL,ui=const,ci=c(0,0,0,-1,0,0,0),outer.eps = .Machine$double.eps)

mle_cox_PG



w(mle_cox_PG$par)

F_x_2_inv <- function(u,theta,lambda,alpha){
  (1-u)^(-1/alpha) * (theta+lambda) - lambda
}

F_X_inv <- function(u){
  if(u <= w(mle_cox_PG$par)){
    Fx1_inv (u * FF(mle_cox_PG$par) / w(mle_cox_PG$par) , mle_cox_PG$par[1],mle_cox_PG$par[2],mle_cox_PG$par[3])
  }else{
    F_x_2_inv((u-w(mle_cox_PG$par)) / (1-w(mle_cox_PG$par)),mle_cox_PG$par[4],mle_cox_PG$par[5],mle_cox_PG$par[6])
  }
}
F_d <- w(mle_cox_PG$par)* Fx1(1.2,mle_cox_PG$par[1],mle_cox_PG$par[2],mle_cox_PG$par[3])/FF(mle_cox_PG$par)

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle_cox_PG$par[4],col=3)
title("QQPlot Coxienne2 - Pareto g?n?ralis? cont.")
t1 <- mle_cox_PG$par[4]

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto g?n?ralis? cont.")


f_X <- function(x){
  if(x<=t1){
    w(mle_cox_PG$par)/FF(mle_cox_PG$par) * fx1(x,mle_cox_PG$par[1],mle_cox_PG$par[2],mle_cox_PG$par[3])
  }else{
    (1-w(mle_cox_PG$par))  * f_2(x,mle_cox_PG$par)
  }
}


x <- seq(1,20000,by=1)
plot(x,sapply(x,f_X),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-20,t1+20,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

F_2 <- function(x,para){
  1- ((para[4]+para[5])/(x+para[5]))^(para[6])
}
F_X <- function(x,para){
  if(x <= para[4]){
    w(para) / FF(para) * Fx1(x,para[1],para[2],para[3])}
  else{
    w(para) + (1-w(para)) * F_2(x,para)
  }
}

FFF <- function(x){
  (sapply(x,F_X,para=mle_cox_PG$par)-F_d)/(1-F_d)
}
(AD_cox_PG<- goftest::ad.test(LOSS,FFF))
AIC_cox_PG<- 2 * 6 + 2* mle_cox_PG$value
BSC_cox_PG <- 6 * log(length(LOSS)) + 2*mle_cox_PG$value

# 2.3.14.COXIENNE 2-Pareto G?n?ralis?e choix du t1 --------------------------------------------------


w1 <- 0.95


t1 <- b_ord[floor(w1*length(b_ord))]

w1 <- (1:length(LOSS))[b_ord==t1]/length(LOSS)

LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]
MeanExcess(secura$size/1000000, k=FALSE)
abline(a=NULL, b=NULL, h=NULL, v=t1,col=2)



LOSS_MD <- sort(LOSS[LOSS<=t1])
LOSS_GP <- sort(LOSS[LOSS>t1])


F_1 <- function(x,para){
  Fx1(x,para[1],para[2],para[3])
}

f_2 <- function(x,para){
  (para[1]+t1)^(para[2]) * para[2] / (para[1]+x)^(para[2]+1)
}


f_1 <- function(x,para){
  fx1(x,para[1],para[2],para[3])
}

neg_log_vrais_MD <- function(para){
  -sum(sapply(LOSS_MD,function(l) log(f_1(l,para))))+length(LOSS_MD) * log(F_1(t1,para)-F_1(1.2,para))
}
neg_log_vrais_PG <- function(para){
  -sum(sapply(LOSS_GP,function(l) log(f_2(l,para))))
}


mle_MD_cox <-  constrOptim(c(9.345379e-01, 8.252604e-09, 7.577125e-01),neg_log_vrais_MD,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)
mle_GP <- constrOptim(c(1,1),neg_log_vrais_PG,grad = NULL,ui=c(0,1),ci=0,outer.eps = .Machine$double.eps)

mle_MD_cox
mle_GP

F_X <- function(x,para){
  if(x <= t1){
    w1 * F_1(x,para[1:2])/F_1(t1,para[1:2])
  }
  else{
    w1 + (1-w1) * (1-((para[3]+t1)/(para[3]+x))^(para[4]))
  }  
}


F_x_2_inv <- function(u,lambda,theta,alpha){
  (1-u)^(-1/alpha) * (theta+lambda) -lambda
}

F_X_inv <- function(u){
  if(u <= w1){
    Fx1_inv(u * (F_1(t1,mle_MD_cox$par)-F_1(1.2,mle_MD_cox$par))/ w1 + F_1(1.2,mle_MD_cox$par) ,mle_MD_cox$par[1],mle_MD_cox$par[2],mle_MD_cox$par[3])
  }
  else{
    F_x_2_inv((u-w1) / (1-w1) ,mle_GP$par[1],t1,mle_GP$par[2])
  }  
}
F_d <- w1* F_1(1.2,mle_MD_cox$par)/ F_1(t1,mle_MD_cox$par)

n <- length(LOSS)
p <- (1:n)/(n+1)

plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - PG)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto g?n?ralis?e")

n <- length(LOSS)
p <- (1:n)/(n+1)
x <- t1+0.1
plot(sapply(p[b_ord<=x],F_X_inv),b_ord[b_ord<=x],ylab="Quantiles observ?s",xlab="Quantiles th?oriques (Coxienne2 - PG)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot Coxienne2 - Pareto g?n?ralis?e")

f_X <- function(x){
  if(x<=t1){
    w1/(F_1(t1,mle_MD_cox$par)-F_1(1.2,mle_MD_cox$par)) * f_1(x,mle_MD_cox$par)
  }else{
    (1-w1) * f_2(x,mle_GP$par)
  }
}

x <- seq(1,40000,by=1)
plot(x,sapply(x,f_X),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-50,t1+50,by=1)
plot(x,sapply(x,f_X))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

F_2 <- function(x,para){
  1- ((para[1]+t1)/(x+para[1]))^(para[2])
}
F_X <- function(x){
  if(x <= t1){
    w1 / (F_1(t1,mle_MD_cox$par)-F_1(1.2,mle_MD_cox$par)) * (F_1(x,mle_MD_cox$par)-F_1(1.2,mle_MD_cox$par))
  }else{
    w1 + (1-w1) * F_2(x,mle_GP$par)
  }
}

p_obs <- sapply(b_ord,function(x){F_B(x)})
p_theo <- sapply(b_ord,function(x){ F_X(x)})
stats::ks.test(p_obs,p_theo)

F_d <- F_X(1.2)
FFF <- function(x){
  (sapply(x,F_X)-F_d)/(1-F_d)
}
(AD_cox_PG_2<- goftest::ad.test(LOSS,FFF))
AIC_cox_PG_2<- 2 * 5 - 2* sum(log(sapply(LOSS,f_X)))
BSC_cox_PG_2 <- 5 * log(length(LOSS)) - 2*sum(log(sapply(LOSS,f_X)))



# 2.3.15 Comparaison des r?sultats ----------------------------------------
#avec AIC et BSC

Model <- c("LN-Pa","LN-Pa theta fix","LN-PG","LN-PG theta fix","LN-Pa-Pa","Weibull-Pa","Weibull-Pa theta fix","Weibull-PG","Weibull-Pa theta fix","Weibull-Pa-Pa","Cox2-Pa","Cox2-Pa theta fix","Cox2-PG","Cox2-PG theta fix")
AIC <- c(AIC_LN_pa,AIC_LN_pa_2,AIC_LN_PG,AIC_LN_PG_2,AIC_LN_pa_pa,AIC_Wei_pa,AIC_Wei_pa_2,AIC_Wei_PG,AIC_Wei_PG_2,AIC_Wei_pa_pa,AIC_cox_pa,AIC_cox_pa_2,AIC_cox_PG,AIC_cox_PG_2)
BSC <- c(BSC_LN_pa,BSC_LN_pa_2,BSC_LN_PG,BSC_LN_PG_2,BSC_LN_pa_pa,BSC_Wei_pa,BSC_Wei_pa_2,BSC_Wei_PG,BSC_Wei_PG_2,BSC_Wei_pa_pa,BSC_cox_pa,BSC_cox_pa_2,BSC_cox_PG,BSC_cox_PG_2)
AD_STAT <-  c(AD_LN_Pa$statistic,AD_LN_Pa_2$statistic,AD_LN_PG$statistic,AD_LN_PG_2$statistic,AD_LN_Pa_Pa$statistic,AD_Wei_Pa$statistic,AD_Wei_Pa_2$statistic,AD_Wei_PG$statistic,AD_Wei_PG_2$statistic,AD_Wei_Pa_Pa$statistic,AD_cox_pa$statistic,AD_cox_pa_2$statistic,AD_cox_PG$statistic,AD_cox_PG_2$statistic) 
AD_p <- c(AD_LN_Pa$p.value,AD_LN_Pa_2$p.value,AD_LN_PG$p.value,AD_LN_PG_2$p.value,AD_LN_Pa_Pa$p.value,AD_Wei_Pa$p.value,AD_Wei_Pa_2$p.value,AD_Wei_PG$p.value,AD_Wei_PG_2$p.value,AD_Wei_Pa_Pa$p.value,AD_cox_pa$p.value,AD_cox_pa_2$p.value,AD_cox_PG$p.value,AD_cox_PG_2$p.value)
choix <- cbind(1:14,AIC,BSC,AD_STAT,AD_p)
result <- data.frame("Mod?le-S?v?rit? Norwegian Fire"=Model,AIC,BSC,AD_STAT,AD_p)

result
(choix_AIC <- choix[order(AIC),])
(choix_BSC <- choix[order(BSC),])

result[4,]
result[2,]
result[7,]

R <- 2*(LOG_VRAIS_LN_PG-LOG_VRAIS_LN_Pa)
qchisq(0.95,1)
qchisq(0.9,1)

R > qchisq(0.95,1)
##on choisit la LN-Pareto simple

###Comparer la LN-Pareto avec une pareto


##Fit pareto
neg_log_vrais <- function(para){
  -sum(log(dpareto(LOSS,para[1],para[2])/(1-ppareto(1.2,para[1],para[2]))))
}


mle_pareto <- constrOptim(c(1.53, 1), neg_log_vrais, grad = NULL, 
                          ui = diag(2), ci = c(0, 0),outer.eps = .Machine$double.eps)

mle_pareto$par



F_pareto_inv <- function(u){
  (mle_pareto$par[2]+1.2) / (1-u)^(1/mle_pareto$par[1]) - mle_pareto$par[2]
}


p <- sapply(b_ord,function(x){F_B(x)})
plot(b_ord,sapply(p,F_pareto_inv),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (pareto)")
lines(b_ord,b_ord,col='red')


p_obs <- sapply(b_ord,function(x){F_B(x)})
p_theo <- (ppareto(b_ord,mle_pareto$par[1],mle_pareto$par[2])-ppareto(1.2,mle_pareto$par[1],mle_pareto$par[2]))/(1-ppareto(1.2,mle_pareto$par[1],mle_pareto$par[2]))
stats::ks.test(p_obs,p_theo)

###

AIC_Pa <- 2 * 2+ 2* mle_pareto$value
BSC_Pa <- 2 * log(length(LOSS)) + 2* mle_pareto$value
AIC_Pa < AIC_LN_pa
BSC_Pa < BSC_LN_pa
(R <- 2*(LOG_VRAIS_LN_Pa+mle_pareto$value))
qchisq(0.99,1)
R > qchisq(0.99,1)
###on choisit le mod?le LN-Pa


# 2.4.Aggregation ---------------------------------------------------------

#### Secura
## ModÃ¨le de sÃ©vÃ©ritÃ© retenu : Splicing d'une Log Normal avec une Pareto
## ModÃ¨le de frÃ©quence retenu : Processus Poisson nonhomog?ne cyclique (cos)
##
## AgrÃ©gation des risques : 
##
## On agrÃ¨ge les risque sur un an (365 jours)
##
## Algorithme d'agrÃ©gation

# 2.4.1.Definition --------------------------------------------------------------
library("ReIns")

data("secura")

LOSS <- secura$size/1000000
b_ord <- LOSS[order(LOSS)]

theta <- 3.2638383 
alpha <- 3.5405219 
sigma <- 0.4162157
para_mle <- c(theta,alpha,sigma)

mu <- function(para){
  log(para[1]) - para[2] * para[3]^2
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}
F1 <- FF(para_mle)
w <- function(para){
  FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]^2*para[3]^2/2) / (1+FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]^2*para[3]^2/2))
}
w1 <- w(para_mle)
mu1 <- mu(para_mle)


F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv <- function(u){
  if(u <= w(para_mle)){
    qlnorm(u * FF(para_mle) / w(para_mle) , mu(para_mle), para_mle[3])
  }else{
    F_x_2_inv((u-w(para_mle)) / (1-w(para_mle)),para_mle[2],para_mle[1])
  }
}
F_d <- w(para_mle)*plnorm(1.2,mu(para_mle),para_mle[3])/FF(para_mle)
t1 <-theta
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(sapply(p,F_X_inv),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (log norm - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
title("QQPlot LN-Pa cont. et d?riv.")

#Simuation 

a <- 25.59688
b <- 29.99606
c <- 15.04107
set.seed(1734176512)
n <- 10^5
t <- 14

Lambda <-function(t,para){
  para[1] * t - para[2] * sin(2 *pi *t /para[3])
}
para_pois_mle <- c(a,b,c)

rPP1 <- function(lam,F_inv){
  N <- rpois(1,lam)
  X <- sapply(runif(N)*(1-F_d)+F_d,F_inv)
  sum(X)
}
F_X_inv(F_d)
S <- replicate(n,rPP1(Lambda(t+1,para_pois_mle)-Lambda(t,para_pois_mle),F_X_inv))

summary(S)
## Validation
E_X1_tr <- function(d){
  exp(mu1+sigma^2 / 2) * (1- pnorm((log(d)-mu1-sigma^2)/sigma))
}
E_X2_tr <- function(d){
  alpha * theta^alpha * d^(1-alpha) / (alpha-1)
}

(E_X <- 1/(1-F_d) * ( w1 / F1 * (E_X1_tr(1.2)-E_X1_tr(theta)) + (1-w1) * E_X2_tr(theta)))#esperance theo du splice

data.frame(Esperance.theorique= (Lambda(t+1,para_pois_mle)-Lambda(t,para_pois_mle))*E_X,Esperance.empirique=mean(S))

# 2.4.2. Mesures de risque ----
S.sorted_Sec <- sort(S)
VaR_ <- function(k) S.sorted_Sec[floor(k*n)]
VaR_S <- c(VaR_(0.90),
           VaR_(0.95),
           VaR_(0.99),
           VaR_(0.999),
           VaR_(0.9999))

TVaR_ <- function(k) mean(S.sorted_Sec[(floor(k*n+1)):n])
TVaR_S <- c(TVaR_(0.90),
            TVaR_(0.95),
            TVaR_(0.99),
            TVaR_(0.999),
            TVaR_(0.9999))

kappa <- c(0.9,0.95,0.99,0.999,0.9999)

data.frame("Kappa"=kappa,"VaR"=VaR_S,"TVaR"=TVaR_S)


sapply(unique(secura$year),function(i) sum(secura$size[secura$year==i]))/1000000
# En conclusion, r?sultat acceptable

# 3.Danish ------------------------------------------------------------------
data(danish)
LOSS <- danish$FIRE.LOSSES
b_ord <- sort(LOSS)

d1 = '1980-01-01'; d2 = '1990-12-01'; dd1 = as.Date(d1); dd2 = as.Date(d2); 
t <- 1:3988
#les nombres de jours entre les deux dates
days <- seq(as.Date('1980-01-01'), as.Date('1990-12-01'), by="days")
#extraire le dates de la base de donn?es pour compter les sinistres
count <- substr(danish.df[,1], 1, 10)


n_day <- sapply(days,function(t){
  sum(count==t)  
})#nombre d observation par jour 

#Graphique freq
plot(n_day[1:1000],type='h',main="",xlab="jours",ylab="Nb de sinistres")
title("Histogramme du nombre de sinistres par jour.")


n_day
plot(t,cumsum(n_day),type="l",ylab="Nombre cumulÃ©",main="Fonction cumulative")
abline(1,.5,col="blue")
#Graphique Sev


summary(LOSS)

MeanExcess(LOSS, k=FALSE,main = "")
title("Fonction d'exc?s moyen")

hist(LOSS,main = "")
title("Histogramme du montant des r?clamations")
ExpQQ(LOSS)
ParetoQQ(LOSS)
# 3.1.Analyse Frequence -------------------------------------------------------
#Processus de Poisson - Homog?ne

#Le mle d'un PPH est la moyenne empirique
mle_homo <- mean(n_day)
#On calcule le log de la vraisemblance pour faire un teste de ratio
l_vrais_homo <- sum(log(dpois(n_day,mle_homo)))

#Processus de Poisson - Nonhomog?ne - Intensit? lin?aire

neg_log_vrais <- function(para){
  -sum(log(dpois(n_day,para[1] + para[2] * (2*(t-1)+1) / 2)))
}

mle_nonhomo <- constrOptim(c(0.05, 0), neg_log_vrais, grad = NULL, 
                           ui = c(1,0), ci = 0,outer.eps = .Machine$double.eps)
#Mle du PPNH
mle_nonhomo$par

#test visuel d'ad?quation avec la fr?quence cumul?e
plot(t,cumsum(n_day))
lines(t,mle_nonhomo$par[1]*(t) + mle_nonhomo$par[2]*(t)^2 / 2,col='red')
lines(t, mean(n_day)*(t),col='green')
#Le PPNH (rouge) semble plus ad?quate

#V?rification si N(t)/t tends vers la moyenne (Test pour PP)
plot(t,cumsum(n_day)/(t),type = "l",ylab = "N(t)/t",xlab="t")
lines(t,rep(mean(n_day),length(t)),col='red')
#N(t)/t tends clairement vers la moyenne. Il s'agit donc d'un processus de poisson

#Estimation des nombres de sinistre pour le 1ier janvier 1991
(estim <- mle_nonhomo$par[1]*3989 + mle_nonhomo$par[2]*3989^2 / 2-mle_nonhomo$par[1]*3988 - mle_nonhomo$par[2]*3988^2 / 2)
# Le nombre esp?r? de sinistre pour 01-01-1991 est 0.65
dpois(0,estim)
dpois(1,estim)
dpois(2,estim)
#On compare avec les prob d'un PPH
dpois(0,mean(n_day))
dpois(1,mean(n_day))
dpois(2,mean(n_day))
#le choix entre PPH et PPNH a donc un impacte consid?rable (sp?cifiquement sur la prob d'avoir 0 sinistres dans un jour)
estim<mean(n_day)

#test de ratio de vraisemblance
R <- 2*(-mle_nonhomo$value-l_vrais_homo)
qchisq(0.95,1)
1-pchisq(R,1)
#On rejette H0 (PPH) --> On choisit PPNH 

#Processus de Poisson - Nonhomog?ne - Intensit? exponentielle

intensite <- function(t,para){
  (para[1] * t)^para[2]
}

neg_log_vrais <- function(para){
  -sum(log(dpois(n_day,intensite(t,para)-intensite(t-1,para))))
}

mle_nonhomo_wei <- constrOptim(c(1, 1), neg_log_vrais, grad = NULL, 
                               ui = c(1,0), ci = 0,outer.eps = .Machine$double.eps)
mle_nonhomo_wei$par

#test visuel d'ad?quation avec la fr?quence cumul?e
plot(t,cumsum(n_day))
lines(t,intensite(t,mle_nonhomo_wei$par),col='blue')
lines(t,mle_nonhomo$par[1]*(t) + mle_nonhomo$par[2]*(t)^2 / 2,col='red')
lines(t, mean(n_day)*(t),col='green')
#Presque pas de diff?rence
# On fait pas un mod?le avec des saison

# 3.2.Analyse severite univariee ------------------------------------------

#Fonction de r?partition empirique
F_B <- function(x){
  sum(LOSS<=x)/length(LOSS)
}
F_B(10)

#3.2.1 Loi exponentielle
neg_log_vrais <- function(para){
  -sum(log(dexp(LOSS,1/para)/(1-pexp(1,1/para))))
}

mle_exp <- optimize(neg_log_vrais,c(0,3000),tol=.Machine$double.eps)
mle_exp$minimum
mean(LOSS)-1

p <- sapply(b_ord,function(x){F_B(x)})
plot(b_ord,qexp(p, 1/mle_exp$minimum)+1,xlab="Quantiles observ?s",ylab="Quantiles th?oriques (expo)")
lines(b_ord,b_ord,col='red')

# 3.2.2. Loi Pareto (2 param?tres)

detach("package:ReIns", unload=TRUE)

neg_log_vrais <- function(para){
  -sum(log(dpareto(LOSS,para[1],para[2])/(1-ppareto(1,para[1],para[2]))))
}


mle_pareto <- constrOptim(c(1, 1), neg_log_vrais, grad = NULL, 
                          ui = diag(2), ci = c(0, 0),outer.eps = .Machine$double.eps)

mle_pareto$par
##Esp?rance th?orique

mle_pareto$par[2]*((mle_pareto$par[1]/(mle_pareto$par[1]-1)*(1-ppareto(1,mle_pareto$par[1],mle_pareto$par[2]))^(-1/mle_pareto$par[1]))-1)
mean(LOSS)
F_X <- function(x){
  (  ppareto(x,mle_pareto$par[1],mle_pareto$par[2])-ppareto(1,mle_pareto$par[1],mle_pareto$par[2])) / (1-ppareto(1,mle_pareto$par[1],mle_pareto$par[2]))
}

F_pareto_inv <- function(u){
  (mle_pareto$par[2]+1) / (1-u)^(1/mle_pareto$par[1]) - mle_pareto$par[2]
}


p <- sapply(b_ord,function(x){F_B(x)})
p <- p+(1-p)*ppareto(1,mle_pareto$par[1],mle_pareto$par[2])
plot(qpareto(p,mle_pareto$par[1],mle_pareto$par[2]),b_ord,ylab="Quantiles observ?s",xlab="Quantiles th?oriques (pareto)")
lines(b_ord,b_ord,col='red')


# 3.2.3. Loi Gamma
#1
neg_log_vrais <- function(para){
  -sum(log(dgamma(LOSS[LOSS<10],para[1], para[2]))) - length(LOSS[LOSS < 10]) * log(1-pgamma(1, para[1], para[2]))
}


mle_gamma <- constrOptim(c(1, 1/30), neg_log_vrais, grad = NULL, 
                         ui = diag(2), ci = c(0,0),outer.eps = .Machine$double.eps)
mle_gamma$par

mle_gamma$par[1]/mle_gamma$par[2]

hist(LOSS[LOSS<10],probability = TRUE)
curve(dgamma(x,mle_gamma$par[1],mle_gamma$par[2]),add=TRUE)


###2
neg_log_vrais <- function(para){
  -sum(log(dgamma(LOSS[LOSS<10],para[1],para[2])))
}


mle_gamma <- constrOptim(c(0.05, 1/35000), neg_log_vrais, grad = NULL, 
                         ui = diag(2), ci = c(0,0),outer.eps = .Machine$double.eps)
mle_gamma$par

mle_gamma$par[1]/mle_gamma$par[2]



p <- sapply(b_ord[b_ord<10],function(x){F_B(x)})
p <- p + (1-p) * pgamma(1,mle_gamma$par[1],mle_gamma$par[2])
plot(b_ord[b_ord<10],qgamma(p, mle_gamma$par[1], mle_gamma$par[2]),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (pareto)")
lines(b_ord[b_ord<10],b_ord[b_ord<10],col='red')

# 3.2.4. Loi log normale
neg_log_vrais <- function(para){
  -sum(log(dlnorm(LOSS,para[1],para[2])/(1-plnorm(1,para[1],para[2]))))
}


mle_lnorm <- constrOptim(c(1, 1), neg_log_vrais, grad = NULL, 
                         ui = c(0,1), ci = 0,outer.eps = .Machine$double.eps)
mle_lnorm$par

exp(mle_lnorm$par[1]+mle_lnorm$par[2]^2/2)

p <- sapply(b_ord,function(x){F_B(x)})
p <- p + (1-p) * plnorm(1,mle_lnorm$par[1],mle_lnorm$par[2])
plot(b_ord, qlnorm(p,mle_lnorm$par[1],mle_lnorm$par[2]),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (log norm)")
lines(b_ord,b_ord,col='red')

p <- sapply(b_ord[b_ord<30],function(x){F_B(x)})
p <- p + (1-p) * plnorm(1,mle_lnorm$par[1],mle_lnorm$par[2])
plot(b_ord[b_ord<30],qlnorm(p,mle_lnorm$par[1],mle_lnorm$par[2]),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (log norm)")
lines(b_ord[b_ord<30],b_ord[b_ord<30],col='red')

p <- sapply(b_ord[b_ord<10],function(x){F_B(x)})
p <- p + (1-p) * plnorm(1,mle_lnorm$par[1],mle_lnorm$par[2])
plot(b_ord[b_ord<10],qlnorm(p,mle_lnorm$par[1],mle_lnorm$par[2]),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (log norm)")
lines(b_ord[b_ord<10],b_ord[b_ord<10],col='red')


# 3.3.Analyse severite splicing -------------------------------------------

# 3.3.1.LN-Pareto (continue & d?rivable) ------------------------------------------------------------------

mu <- function(para){
  log(para[1]) - para[2] * para[3]^2
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}

w <- function(para){
  FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]*para[3]^2/2) / (1+FF(para) * para[2] * para[3] * sqrt(2*pi) * exp(para[2]*para[3]^2/2))
}


f_1 <- function(x,para){
  dlnorm(x,mu(para),para[3])
}
f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* plnorm(1,mu(para),para[3])/FF(para))
}


mle <- constrOptim(c(1.6,1.4,0.47),neg_log_vrais,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)

mle

mu(mle$par)

w(mle$par)

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv <- function(u){
  if(u <= w(mle$par)){
    qlnorm(u * FF(mle$par) / w(mle$par) , mu(mle$par), mle$par[3])
  }else{
    F_x_2_inv((u-w(mle$par)) / (1-w(mle$par)),mle$par[2],mle$par[1])
  }
}
F_d <- w(mle$par)*plnorm(1,mu(mle$par),mle$par[3])/FF(mle$par)

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(b_ord,sapply(p,F_X_inv),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (log norm - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle$par[1],col=3)
######LN- Pareto GENERALE

# 3.3.2.LN-Pareto G?n?ralis?e (continue & d?rivable) -------------------------------------------------------------

LOSS <- danish$FIRE.LOSSES
b_ord <- LOSS[order(LOSS)]

mu <- function(para){
  (log(para[1]) - para[2]*para[1] * para[3]^2 / (para[4]+para[1])) / (1 - para[3]^2 / (para[4]+para[1]))
}
FF <- function(para){
  plnorm(para[1],mu(para),para[3])
}

w <- function(para){
  FF(para) * para[1] * para[2] * para[3] * sqrt(2*pi) * exp( (log(para[1])-mu(para))^2 / (2*para[3]^2 )) / (para[1]+para[4]+FF(para) * para[1] * para[2] * para[3] * sqrt(2*pi) * exp( (log(para[1])-mu(para))^2 / (2*para[3]^2 )))
}


f_1 <- function(x,para){
  dlnorm(x,mu(para),para[3])
}
f_2 <- function(x,para){
  para[2] * (para[1]+para[4])^para[2] / (para[4]+x)^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* plnorm(1,mu(para),para[3])/FF(para))
}




mle <- constrOptim(c(1.85,1.38,0.57,-0.05),neg_log_vrais,grad = NULL,ui=matrix(c(1,0,0,0,1,0,0,0,1,0,0,0),3,4),ci=c(0,0,0),outer.eps = .Machine$double.eps)


mle

FF(mle$par)

w(mle$par)

F_x_2_inv <- function(u,alpha,theta,lambda){
  (1-u)^(-1/alpha) * (theta+lambda) - lambda
}
F_X_inv <- function(u){
  if(u <= w(mle$par)){
    qlnorm(u * FF(mle$par) / w(mle$par) , mu(mle$par), mle$par[3])
  }else{
    F_x_2_inv((u-w(mle$par)) / (1-w(mle$par)),mle$par[2],mle$par[1],mle$par[4])
  }
}
F_d <- w(mle$par)*plnorm(1,mu(mle$par),mle$par[3])/FF(mle$par)

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(b_ord,sapply(p,F_X_inv),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (log norm - GPD)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle$par[1],col=3)
###### LN - pareto -pareto , 6 parametres

# 3.3.3.LN-Pareto-Pareto----------------------------------------------------------

LOSS <- danish$FIRE.LOSSES
b_ord <- LOSS[order(LOSS)]

FF12 <- function(para){
  1-(para[2]/para[4])^(para[3])
}

mu <- function(para){
  log(para[2])-para[1]^2 * para[3] 
}

w1 <- function(para){
  sqrt(2 * pi) *para[1] * para[3] *exp(para[1]^2 *para[3]^2 /2) * FF(para) / ( sqrt(2 * pi) *para[1] * para[3] *exp(para[1]^2 *para[3]^2 /2) * FF(para) + 1)
}

w2 <- function(para){
  FF12(para) / ( sqrt(2 * pi) *para[1] * para[3] *exp(para[1]^2 *para[3]^2 /2) * FF(para) + 1)
}

FF <- function(para){
  plnorm(para[2],mu(para),para[1])
}

f_1 <- function(x,para){
  dlnorm(x,mu(para),para[1])
}
f_2 <- function(x,para){
  para[3] * para[2]^para[3] / x^(para[3]+1)
}
f_3 <- function(x,para){
  para[3] * para[4]^para[3] / x^(para[3]+1)
}




f_X <- function(x,para){
  if(x<=para[2]){
    w1(para)/FF(para) * f_1(x,para)
  }else if(x<=para[4]){
    w2(para)/FF12(para) * f_2(x,para)
  }else{
    (1-w1(para)-w2(para)) * f_3(x,para)
  } 
}


F_X <- function(x,para){
  if(x <= para[2]){
    w1(para) * plnorm(x,mu(para),para[1])/FF(para)
  }
  else if(x<=para[4]){
    w1(para) + w2(para) * (1-(para[2]/x)^(para[3]) )/FF12(para)
  }  
  else{
    w1(para) + w2(para) + (1-w1(para)-w2(para)) * (1-(para[4]/x)^(para[3]) )
  }
}


F_1 <- function(x,para){
  plnorm(x,mu(para),para[1])
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w1(para) * plnorm(1,mu(para),para[1])/FF(para))
}



mle <-  constrOptim(c(0.8,8,1,18),neg_log_vrais,grad = NULL,ui=diag(4),ci=c(0,0,0,0),outer.eps = .Machine$double.eps)


mle

F_x_2_inv <- function(u,theta,alpha){
  theta * (1-u)^(-1/alpha)
}

F_X_inv <- function(u,para){
  if(u <= w1(para)){
    qlnorm(u * FF(para)/ w1(para) ,mu(para),para[1])
  }
  else if(u<=(w1(para)+w2(para))){
    F_x_2_inv((u-w1(para)) * FF12(para) / w2(para) ,para[2],para[3])
  }  
  else{
    F_x_2_inv((u-w1(para)-w2(para)) / (1-w1(para)-w2(para)),para[4],para[3])
  }
}
F_d <- w1(mle$par)* F_1(1,mle$par)/ FF(mle$par)

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p + F_d *(1-p)


F_d <- w1(mle$par)* F_1(1,mle$par)/ FF(mle$par)
t1 <- mle$par[2]
t2 <- mle$par[4]

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p + F_d *(1-p)

plot(b_ord,sapply(p,F_X_inv,para=mle$par),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (LN - pareto -pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
abline(a=NULL, b=NULL, h=NULL, v=t2,col=3)


x <- t1+4
plot(b_ord[b_ord<=x],sapply(p[b_ord<=x],F_X_inv,para=mle$par),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (Weibull - pareto -pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)


x <- seq(1,50,by=0.01)
plot(x,sapply(x,f_X,para=mle$par),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)

x <- seq(t1-1,t1+1,by=0.01)
plot(x,sapply(x,f_X,para=mle$par))
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
x <- seq(t2-1,t2+1,by=0.01)
plot(x,sapply(x,f_X,para=mle$par))
abline(a=NULL, b=NULL, h=NULL, v=t2,col=3)

###### Weibull - pareto

# 3.3.4.Weibull-Pareto (continue & d?rivable) -----------------------------------------------------------


LOSS <- danish$FIRE.LOSSES
b_ord <- LOSS[order(LOSS)]

beta <- function(para){
  para[1] / (para[2]/para[3]+1)^(1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}

pexp(1,2)
pweibull(1,1,0.5)

w <- function(para){
  (exp(para[2]/para[3]+1)-1) / (exp(para[2]/para[3]+1)+para[3]/para[2])
}


f_1 <- function(x,para){
  dweibull(x,para[3],beta(para))
}
f_2 <- function(x,para){
  para[2] * para[1]^para[2] / x^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* pweibull(1,para[3],beta(para))/FF(para))
}




mle <- constrOptim(c(1.5,3.5,2),neg_log_vrais,grad = NULL,ui=diag(3),ci=c(0,0,0),outer.eps = .Machine$double.eps)

mle

mu(mle$par)

w(mle$par)

F_x_2_inv <- function(u,alpha,theta){
  (1-u)^(-1/alpha) * theta
}
F_X_inv <- function(u){
  if(u <= w(mle$par)){
    qweibull(u * FF(mle$par) / w(mle$par) , mle$par[3],beta(mle$par))
  }else{
    F_x_2_inv((u-w(mle$par)) / (1-w(mle$par)),mle$par[2],mle$par[1])
  }
}
F_d <- w(mle$par)*pweibull(1,mle$par[3],beta(mle$par))/FF(mle$par)
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(b_ord,sapply(p,F_X_inv),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (Weibull - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle$par[1],col=3)

# 3.3.5.Weibull-Pareto G?n?ralis?e (continue & d?rivable) --------------------------------------------------------

LOSS <- danish$FIRE.LOSSES
b_ord <- LOSS[order(LOSS)]

beta <- function(para){
  para[1] * ( (para[2] * para[1] -para[4])/ ((para[4]+para[1])*para[3]) + 1)^(-1/para[3])
}
FF <- function(para){
  pweibull(para[1],para[3],beta(para))
}

w <- function(para){
  (exp((para[1]/beta(para))^para[3])-1) / ( (para[3]/para[2]) * (para[4]/para[1]+1) * (para[1]/beta(para))^para[3] +  exp((para[1]/beta(para))^para[3])-1) 
}

f_1 <- function(x,para){
  dweibull(x,para[3],beta(para))
}
f_2 <- function(x,para){
  para[2] * (para[1]+para[4])^para[2] / (para[4]+x)^(para[2]+1)
}

f_X <- function(x,para){
  if(x<=para[1]){
    w(para)/FF(para) * f_1(x,para)
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* pweibull(1,para[3],beta(para))/FF(para))
}




mle <- constrOptim(c(2.9,3.96,2,0.37),neg_log_vrais,grad = NULL,ui=matrix(c(1,0,0,0,1,0,0,0,1,0,0,0),3,4),ci=c(0,0,0),outer.eps = .Machine$double.eps)


mle

mu(mle$par)

w(mle$par)

F_x_2_inv <- function(u,alpha,theta,lambda){
  (1-u)^(-1/alpha) * (theta+lambda) - lambda
}
F_X_inv <- function(u){
  if(u <= w(mle$par)){
    qweibull(u * FF(mle$par) / w(mle$par) , mle$par[3],beta(mle$par))
  }else{
    F_x_2_inv((u-w(mle$par)) / (1-w(mle$par)),mle$par[2],mle$par[1],mle$par[4])
  }
}
F_d <- w(mle$par)*pweibull(1,mle$par[3],beta(mle$par))/FF(mle$par)
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(b_ord,sapply(p,F_X_inv),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (Weibull - GPD)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle$par[1],col=3)

summary(LOSS)
###### Weibull - pareto -pareto , 6 parametres

# 3.3.6.Weibull-Pareto-Pareto -----------------------------------------------------

LOSS <- danish$FIRE.LOSSES
b_ord <- LOSS[order(LOSS)]

FF12 <- function(para){
  1-(para[2]/para[4])^(para[3])
}

beta <- function(para){
  para[2] * (para[3]/para[1]+1)^(-1/para[1])
}

w1 <- function(para){
  (exp(para[3]/para[1]+1)-1) / (exp(para[3]/para[1]+1)+para[1]/para[3])
}

w2 <- function(para){
  FF12(para) * (para[1]+para[3]) / (exp(para[3]/para[1]+1)*para[3]+para[1])
}

FF <- function(para){
  pweibull(para[2],para[1],beta(para))
}

f_1 <- function(x,para){
  dweibull(x,para[1],beta(para))
}
f_2 <- function(x,para){
  para[3] * para[2]^para[3] / x^(para[3]+1)
}
f_3 <- function(x,para){
  para[3] * para[4]^para[3] / x^(para[3]+1)
}

f_X <- function(x,para){
  if(x<=para[2]){
    w1(para)/FF(para) * f_1(x,para)
  }else if(x<=para[4]){
    w2(para)/FF12(para) * f_2(x,para)
  }else{
    (1-w1(para)-w2(para)) * f_3(x,para)
  } 
}


F_X <- function(x,para){
  if(x <= para[2]){
    w1(para) * pweibull(x,para[1],beta(para))/FF(para)
  }
  else if(x<=para[4]){
    w1(para) + w2(para) * (1-(para[2]/x)^(para[3]) )/FF12(para)
  }  
  else{
    w1(para) + w2(para) + (1-w1(para)-w2(para)) * (1-(para[4]/x)^(para[3]) )
  }
}


F_1 <- function(x,para){
  pweibull(x,para[1],beta(para))
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w1(para) *  pweibull(1,para[1],beta(para))/FF(para))
}



mle <-  constrOptim(c(2,3,3.5,4),neg_log_vrais,grad = NULL,ui=diag(4),ci=c(0,0,0,0),outer.eps = .Machine$double.eps)


mle

F_x_2_inv <- function(u,theta,alpha){
  theta * (1-u)^(-1/alpha)
}

F_X_inv <- function(u,para){
  if(u <= w1(para)){
    qweibull(u * FF(para)/ w1(para) ,para[1],beta(para))
  }
  else if(u<=(w1(para)+w2(para))){
    F_x_2_inv((u-w1(para)) * FF12(para) / w2(para) ,para[2],para[3])
  }  
  else{
    F_x_2_inv((u-w1(para)-w2(para)) / (1-w1(para)-w2(para)),para[4],para[3])
  }
}
F_d <- w1(mle$par)* F_1(1,mle$par)/ FF(mle$par)
t1 <- mle$par[2]
t2 <- mle$par[4]

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p + F_d *(1-p)

plot(b_ord,sapply(p,F_X_inv,para=mle$par),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (Weibull - pareto -pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
abline(a=NULL, b=NULL, h=NULL, v=t2,col=3)

x <- t1+0.1
plot(b_ord[b_ord<=x],sapply(p[b_ord<=x],F_X_inv,para=mle$par),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (Weibull - pareto -pareto)")
lines(b_ord[b_ord<=x],b_ord[b_ord<=x],col='red')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)


x <- seq(1,6,by=0.01)
plot(x,sapply(x,f_X,para=mle$par),type='l')
abline(a=NULL, b=NULL, h=NULL, v=t1,col=3)
abline(a=NULL, b=NULL, h=NULL, v=t2,col=3)




# Coxienne2 ---------------------------------------------------------------


#Fonction de la loi Coxienne2
fx1 <- function(x,beta1,beta2,p){
  p * beta1*exp(-beta1*x) + (1-p)*(beta1*beta2)* ( exp(-beta1*x)/(beta2-beta1) + exp(-beta2*x)/(beta1-beta2) )
}
fx1_d <- function(x,beta1,beta2,p){
  -p * beta1^2*exp(-beta1*x) + (1-p)*beta1*beta2* ( - beta1 * exp(-beta1*x)/(beta2-beta1) - beta2 *exp(-beta2*x)/(beta1-beta2) )
}


Fx1 <- function(x,beta1,beta2,p){
  p * (1-exp(-beta1*x)) + (1-p) * ( beta2 * (1-exp(-beta1*x))/(beta2-beta1) + beta1 *(1-exp(-beta2*x))/(beta1-beta2)
  )}

Fx1_inv <- function(k,beta1,beta2,p){ 
  uniroot(function(x) Fx1(x,beta1,beta2,p) - k, c(0,10^9))$root
}

# 3.3.7.COXIENNE 2-Pareto (continue) ------------------------------------

LOSS <- danish$FIRE.LOSSES
b_ord <- LOSS[order(LOSS)]

FF <- function(para){
  Fx1(para[4],para[1],para[2],para[3])
}


w <- function(para){
  FF(para) / ( FF(para) + para[4]/para[5] * fx1(para[4],para[1],para[2],para[3]))
}


f_2 <- function(x,para){
  para[5] * para[4]^para[5] * x^(-para[5]-1)
}

f_X <- function(x,para){
  if(x<=para[4]){
    w(para)/FF(para) * fx1(x,para[1],para[2],para[3])
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* Fx1(1,para[1],para[2],para[3])/FF(para))
}
f_2(10000,test)


const <- matrix(c(1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,1,0,0,0,0,0,0,1),6,5)
test <- c(1/1, 1/2,0.5,3,2)


mle <- constrOptim(test,neg_log_vrais,grad = NULL,ui=const,ci=c(0,0,0,-1,0,0),outer.eps = .Machine$double.eps)

mle



w(mle$par)

F_x_2_inv <- function(u,theta,alpha){
  theta * (1-u)^(-1/alpha)
}


F_X_inv <- function(u){
  if(u <= w(mle$par)){
    Fx1_inv (u * FF(mle$par) / w(mle$par) , mle$par[1],mle$par[2],mle$par[3])
  }else{
    F_x_2_inv((u-w(mle$par)) / (1-w(mle$par)),mle$par[4],mle$par[5])
  }
}
F_d <- w(mle$par)* Fx1(1,mle$par[1],mle$par[2],mle$par[3])/FF(mle$par)

n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(b_ord,sapply(p,F_X_inv),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (COXIENNE 2 - pareto)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle$par[5],col=3)
###### COXIENNE 2 - pareto GE

# 3.3.8.COXIENNE 2-Pareto G?n?ralis?e (continue) ------------------------------------------------------

LOSS <- danish$FIRE.LOSSES
b_ord <- LOSS[order(LOSS)]

FF <- function(para){
  Fx1(para[4],para[1],para[2],para[3])
}

w <- function(para){
  FF(para) / ( FF(para) + para[5] * fx1(para[4],para[1],para[2],para[3]))
}


f_2 <- function(x,para){
  1/para[5] * (1 + para[6]/para[5] * (x-para[4]))^(-1-1/para[6])
}

f_X <- function(x,para){
  if(x<=para[4]){
    w(para)/FF(para) * fx1(x,para[1],para[2],para[3])
  }else{
    (1-w(para)) * f_2(x,para)
  } 
}

neg_log_vrais <- function(para){
  -sum(sapply(LOSS,function(l) log(f_X(l,para))))+length(LOSS) * log(1-w(para)* Fx1(1,para[1],para[2],para[3])/FF(para))
}


const <- matrix(c(1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1),7,6)
test <- c(1/1, 1/6,0.8,3,1,1)


w(test)



mle <- constrOptim(test,neg_log_vrais,grad = NULL,ui=const,ci=c(0,0,0,-1,0,0,0),outer.eps = .Machine$double.eps)

mle



w(mle$par)

F_x_2_inv <- function(u,theta,sig,gamma){
  ((1-u)^(-gamma) -1) * sig/gamma + theta
}

F_X_inv <- function(u){
  if(u <= w(mle$par)){
    Fx1_inv (u * FF(mle$par) / w(mle$par) , mle$par[1],mle$par[2],mle$par[3])
  }else{
    F_x_2_inv((u-w(mle$par)) / (1-w(mle$par)),mle$par[4],mle$par[5],mle$par[6])
  }
}
F_d <- w(mle$par)* Fx1(1,mle$par[1],mle$par[2],mle$par[3])/FF(mle$par)
n <- length(LOSS)
p <- (1:n)/(n+1)
p <- p+F_d * (1-p)
plot(b_ord,sapply(p,F_X_inv),xlab="Quantiles observ?s",ylab="Quantiles th?oriques (COXIENNE 2 - GPD)")
lines(b_ord,b_ord,col='red')
abline(a=NULL, b=NULL, h=NULL, v=mle$par[5],col=3)

# 3.4.Aggregation ---------------------------------------------------------
## ModÃ¨le de sÃ©vÃ©ritÃ© retenu : Pareto(1.6356360, 0.5244502)
## ModÃ¨le de frÃ©quence retenu : Processus non homogÃ¨ne avec intensitÃ© qui augmente linÃ©airement
## Les paramÃ¨tres de celui-ci sont 4.283298e-01 et 5.452899e-05
##
## AgrÃ©gation des risques : 
##
## On agrÃ¨ge les risque sur un an (365 jours)
##
## Algorithme d'agrÃ©gation
set.seed(20181129)
n <- 10^5
Alpha <- 1.6356360 ; Teta <- 0.5244502
a <- 4.283298e-01 ; b <- 5.452899e-05
Lambda <- function(t) a + b*(2*t-1)/2
F_d <- ppareto(1,Alpha,Teta)

N <- matrix(sapply(3988:(3988+364),function(t)rpois(n,Lambda(t))),n,365,byrow = F)
dim(N)
X <- qpareto(runif(N)*(1-F_d)+F_d,Alpha,Teta)
S <- matrix(NA,n,365)

i <- 1
for(j in 1:n){
  for(t in 1:365){
    if(N[j,t]==0) S[j,t] <- 0
    else 
    {S[j,t] <- sum(X[i:(i+N[j,t]-1)])
    i <- i+1
    }
  }
}
S.annuel <- sapply(1:n,function(j)sum(S[j,]))
summary(S.annuel)

## Validation
E_X <- Teta*((Alpha/(Alpha-1)*(1-ppareto(1,Alpha,Teta))^(-1/Alpha))-1)##exp?rance conditionnelle

data.frame(Esperance.theorique= sum(sapply(3988:(3988+364),Lambda))*E_X,Esperance.empirique=mean(S.annuel))

## Mesures de risque ----
S.sorted <- sort(S.annuel)
VaR_ <- function(k) S.sorted[floor(k*n)]
VaR_S <- c(VaR_(0.90),
            VaR_(0.95),
            VaR_(0.99),
            VaR_(0.999),
            VaR_(0.9999))
TVaR_ <- function(k) mean(S.sorted[(floor(k*n+1)):n])
TVaR_S <- c(TVaR_(0.90),
            TVaR_(0.95),
            TVaR_(0.99),
            TVaR_(0.999),
            TVaR_(0.9999))

kappa <- c(0.9,0.95,0.99,0.999,0.9999)

data.frame("Kappa"=kappa,"VaR"=VaR_S,"TVaR"=TVaR_S)


## En conclusion, puisqu'une Pareto avec un paramÃ¨tre de forme prÃ¨s de 1 est utilisÃ©e pour modÃ©liser la sÃ©vÃ©ritÃ©,
## Il est plus avisÃ© d'utiliser la TVaR pour estimer le montant de capital Ã  conserver en vu des
## obligations de la prochaine annÃ©e. De cette faÃ§on, pour une compagnie de rÃ©assurance qui couvrirait
## la base de donnÃ©es Danish, il faudrait conserver un montant de 330.624 millions de courronnes danoises.

\end{verbatim}
