\section{Introduction}
	\cite{Parodi2015_Pricing_in_GenIns} décrit la tarification et le calcul du capital comme un processus suivant plusieurs étapes. Chacune de ces étapes est très importantes dans l'établissement des modèles de prédiction. Pour les compagnies de réassurance, il est d'autant plus important d'avoir des modèles prédictifs solides afin d'assurer la pérennité des opérations puisque celles-ci implique de travailler avec des risques comportant des valeurs extrêmes et difficilement prévisibles.\\
	
	À ce sujet, plusieurs ouvrages ont couvert la \textit{théorie des valeurs extrêmes}, notamment, \cite{norwegianfireEtSecura} et \cite{Danish}. Cependant, il ne suffit pas simplement de bien modéliser les montants des sinistres puisque la fréquence à laquelle ces risques élevés se manifestent a une importance cruciale dans le calcul du capital. Ainsi, \cite{albrecher2017reinsurance} vient couvrir le sujet de la modélisation des risques dans le domaine de la réassurance en introduisant les processus de Poisson dans ses modèles de prédiction et en agrégeant les risque d'un portefeuille. \\
	
	Cet ouvrage offre une couverture très complète du sujet. Cependant \cite{brazauskas2016modeling} vient compléter le sujet de la modélisation des montants de sinistre avec une approche plus détaillée du raccordement de lois (\textit{splicing}) puisqu'il explique comment assurer la continuité et la dérivabilité des modèles. De plus, ce dernier propose des modèles de \textit{splicing} qui utilise une plus grande diversité de lois que simplement des mélanges d'Erlangs avec des lois de Pareto, ce qui permet de simplifier les modèles en ayant moins de paramètres.\\
	
	Le présent rapport, quant à lui, permet de mettre en pratique les idées soulevées dans ces ouvrages dans un contexte éducatif, en utilisant des méthodes numériques avec \texttt{R}, et en travaillant avec des outils couramment utilisés dans le domaine de l'actuariat et des statistiques. Ainsi, en travaillant sur trois bases de données bien connues du milieu de la réassurance, l'objectif est de modéliser, adéquatement autant la variable de fréquence que celle de la sévérité, afin de créer un modèle agrégé dont il est possible de mesurer le risque. Également, on peut trouver en annexe du présent rapport, le code \texttt{R} ayant servi à réaliser ce travail.\\
	
	De cette façon, ce rapport pourra servir de référence pour des étudiants gradués ou en fin de parcours universitaire pour se familiariser avec la tarification en réassurance non-vie.\\
	
	Le présent rapport se construit comme suit : Dans la section \ref{Section_AnalysePreliminaire}, une analyse préliminaire est faite afin d'orienter les étapes subséquentes. La première de ces étapes consiste en l'analyse de la fréquence. Cette dernière est présentée dans la section \ref{Section_Frequence} où différents types de processus de Poisson sont proposés. Par la suite, une analyse de la sévérité est décrite dans les sections \ref{Section_Severite} et \ref{Section_Splicing}. Ainsi, en premier lieu, une analyse est faite avec des lois univariées puis, en deuxième 
	lieu, le sujet des raccordements de lois est incorporé afin d'ajouter au pouvoir de prédiction du modèle proposé. Une fois ces analyses effectuées, il faut évaluer lequel des modèles testé est le plus adéquat. De cette façon, une série de tests d'adéquation est décrite dans la section \ref{Sect_Adequation}. Ensuite, une fois un modèle choisit, il est possible d'agréger les risques, comme il est décrit dans la section \ref{Sect_Agregation}, afin de mesurer le risque du portefeuille et d'arriver à des bases de tarification. Finalement, dans la section \ref{Sect_Resultats}, les résultats sont présentés pour chacune des bases de données pour finalement arriver à une conclusion dans la section \ref{Sect_Conclusion}.
	