\section*{Sommaire}
	Dans le domaine de la réassurance, plusieurs ouvrages très complets ont traité de la modélisation des risques et de l'agrégation de ceux-ci. Notamment, mentionnons \cite{albrecher2017reinsurance}, \cite{brazauskas2016modeling}. Également, d'autres ouvrages moins spécialisés viennent compléter certains aspects de la modélisation tels que \cite{LossModels_Klugman2012}.\\
	
	Les sujets clés de ce domaine sont la \textit{théorie des valeurs extrêmes} ainsi que la \textit{théorie des modèles collectifs}.
	Lorsque l'on aborde le sujet de la \textit{théorie des valeurs extrêmes}, on ne peut pas passer à côté du sujet des raccordements de lois (\textit{splicing}) et, bien sûr, de la question à savoir s'il est mieux d'avoir un modèle continue et dérivable ou un modèle qui a une meilleure adéquation globale.\\
	
	Dans ce travail, les étapes de la modélisation décrites par \cite{albrecher2017reinsurance} sont utilisées et complétées par le travail de \cite{LossModels_Klugman2012}.	
	Une analyse de la fréquence est faite suivant différents types de processus de Poisson. Cette analyse est à la fois qualitative et quantitative.
	Une analyse de la sévérité est faite en accord avec l'analyse de la fonction d'excès moyen, tel que proposé par \cite{Embrechts1994}. Cette proposition est d'ailleurs mise en doute dans le présent travail.
	Par la suite, différents modèles sont testés, allant d'une loi à trois lois raccordées, afin de tester les enjeux de continuité ainsi que les modèles proposés par \cite{brazauskas2016modeling}.	
	Ensuite, en utilisant les méthode de sélection de modèle définis par \cite{LossModels_Klugman2012}, des modèles sont sélectionnés pour chacune des bases de données utilisées pour finalement aboutir à l'agrégation des risques afin d'en faire une appréciation et calculer le capital à investir advenant qu'une compagnie de réassurance prendrait ces portefeuilles.	